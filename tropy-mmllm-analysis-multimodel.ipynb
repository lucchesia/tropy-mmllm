{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-intro",
   "metadata": {},
   "source": [
    "# üìÑ Tropy API Multimodal Analysis & Summarization Notebook\n",
    "\n",
    "This notebook offers an integrated, step-by-step workflow for analyzing Tropy collections with **multimodal large language models (MMLMs)**.\n",
    "\n",
    "## ü§ñ Multi-Model Support\n",
    "- **Google Gemini** (gemini-1.5-flash) \n",
    "- **OpenAI GPT-4** (gpt-4o-mini) \n",
    "- **Anthropic Claude** (claude-sonnet-4) \n",
    "- Easy API key configuration with secure `.env` storage\n",
    "\n",
    "## üóÇÔ∏è Main Features\n",
    "- Connects to Tropy‚Äôs local API to extract item and photo metadata\n",
    "- Loads transcriptions (when available) and image files\n",
    "- Generates **photo-level summaries**, prioritizing transcriptions while leveraging image context\n",
    "- Creates **item-level summaries** by synthesizing photo-level content\n",
    "- Optionally produces **semantic embeddings** for advanced search, clustering, or recommendation tasks\n",
    "- Writes results back to Tropy as notes, and also saves outputs to local JSON files\n",
    "- Supports batch checkpointing and resume to handle large collections\n",
    "\n",
    "## ‚ö° Inspiration\n",
    "This workflow builds on and adapts ideas from Taylor Arnold and Lauren Tilton‚Äôs [Explainable Search and Discovery of Visual Cultural Heritage Collections with Multimodal Large Language Models](https://2024.computational-humanities-research.org/papers/paper28/). It was developed for the DH2025 workshop *Transcribing the Vatican Archives: Contextualization, Limits, and Opportunities*, led by Anita Lucchesi and Sean Takats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-setup",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Required Libraries\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from pdf2image import convert_from_path\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "from typing import Optional, List, Dict, Any\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ All dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "api-key-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configure API Keys and Select Model\n",
    "\n",
    "print(\"üîß Setting up AI Model Providers...\\n\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check and configure API keys\n",
    "providers_available = []\n",
    "\n",
    "# Helper function to add/check API key\n",
    "def check_api_key(provider_name, env_var, display_name):\n",
    "    if os.getenv(env_var):\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"üìù {provider_name} API key not found\")\n",
    "        add_key = input(f\"   Add {provider_name} API key? (y/n) [n]: \").strip().lower()\n",
    "        if add_key == 'y':\n",
    "            api_key = input(f\"   Paste your {provider_name} API key: \").strip()\n",
    "            if api_key:\n",
    "                with open('.env', 'a') as f:\n",
    "                    f.write(f\"\\n{env_var}={api_key}\\n\")\n",
    "                load_dotenv()\n",
    "                print(f\"   ‚úÖ Added {provider_name} key to .env\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "# Check each provider\n",
    "print(\"üìä Checking available providers:\\n\")\n",
    "\n",
    "# Google Gemini\n",
    "if check_api_key(\"Google\", \"GOOGLE_API_KEY\", \"Gemini\"):\n",
    "    try:\n",
    "        import google.generativeai as genai  # Import here!\n",
    "        genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "        providers_available.append((\"gemini\", \"Google Gemini (gemini-1.5-flash)\"))\n",
    "    except ImportError:\n",
    "        print(\"   ‚ö†Ô∏è  Google AI library not installed. Run: pip install google-generativeai\")\n",
    "\n",
    "# OpenAI\n",
    "if check_api_key(\"OpenAI\", \"OPENAI_API_KEY\", \"GPT-4\"):\n",
    "    try:\n",
    "        import openai\n",
    "        providers_available.append((\"openai\", \"OpenAI (gpt-4o-mini)\"))\n",
    "    except ImportError:\n",
    "        print(\"   ‚ö†Ô∏è  OpenAI library not installed. Run: pip install openai\")\n",
    "\n",
    "# Anthropic\n",
    "if check_api_key(\"Anthropic\", \"ANTHROPIC_API_KEY\", \"Claude\"):\n",
    "    try:\n",
    "        import anthropic\n",
    "        providers_available.append((\"claude\", \"Anthropic Claude (claude-3.5-sonnet)\"))\n",
    "    except ImportError:\n",
    "        print(\"   ‚ö†Ô∏è  Anthropic library not installed. Run: pip install anthropic\")\n",
    "\n",
    "# Select model\n",
    "print(f\"\\nüìã Available models: {len(providers_available)}\")\n",
    "\n",
    "if len(providers_available) == 0:\n",
    "    print(\"‚ùå No models available. Please configure at least one API key.\")\n",
    "    raise ValueError(\"No API keys configured\")\n",
    "elif len(providers_available) == 1:\n",
    "    selected = providers_available[0]\n",
    "    globals()['selected_model_provider'] = selected[0]\n",
    "    print(f\"‚úÖ Using: {selected[1]}\")\n",
    "else:\n",
    "    print(\"\\nüéØ Select your model:\")\n",
    "    for i, (key, name) in enumerate(providers_available):\n",
    "        print(f\"   {i+1}. {name}\")\n",
    "    \n",
    "    choice = input(f\"\\nYour choice (1-{len(providers_available)}) [1]: \").strip() or \"1\"\n",
    "    try:\n",
    "        idx = int(choice) - 1\n",
    "        selected = providers_available[idx]\n",
    "        globals()['selected_model_provider'] = selected[0]\n",
    "        print(f\"\\n‚úÖ Selected: {selected[1]}\")\n",
    "    except:\n",
    "        selected = providers_available[0]\n",
    "        globals()['selected_model_provider'] = selected[0]\n",
    "        print(f\"\\n‚úÖ Defaulting to: {selected[1]}\")\n",
    "\n",
    "# Quick test\n",
    "print(\"\\nüß™ Testing selected model...\")\n",
    "try:\n",
    "    if globals()['selected_model_provider'] == 'gemini':\n",
    "        # genai is already imported above if Google was selected\n",
    "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        response = model.generate_content(\"Say 'Hello Tropy' in exactly 2 words\")\n",
    "        print(f\"‚úÖ Model test successful: {response.text.strip()}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Model configured (test available after adapter setup)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Test failed: {e}\")\n",
    "    print(\"   Model will be tested when first used\")\n",
    "\n",
    "print(\"\\n‚ú® Setup complete! Ready to process your collection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bbcbdd-0b0e-4be3-b7ba-41c3988226bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Configuration Settings\n",
    "\n",
    "class TropyAIConfig:\n",
    "    \"\"\"Central configuration for the Tropy AI workflow.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # API Settings\n",
    "        self.TROPY_API_BASE = 'http://localhost:2019'\n",
    "        \n",
    "        # Model configuration will be set after user selection\n",
    "        self.GENERATIVE_MODEL = None\n",
    "        self.EMBEDDING_MODEL = None\n",
    "        \n",
    "        # Rate Limits and Delays\n",
    "        self.API_IMAGE_DELAY = 1.5\n",
    "        self.API_NOTE_DELAY = 3.0\n",
    "        self.IMAGE_TIMEOUT = 30\n",
    "        self.RATE_LIMIT_DELAY = 2.0\n",
    "        self.ROLLING_WINDOW_SIZE = 3\n",
    "        \n",
    "        # File Management\n",
    "        self.CHECKPOINT_FILE = \"processing_checkpoint.json\"\n",
    "        self.OUTPUT_DIR = \"./output\"\n",
    "        self.EMBEDDINGS_FILE = \"tropy_embeddings.json\"\n",
    "        \n",
    "        # Batch Processing\n",
    "        self.BATCH_SIZE = 50\n",
    "        self.CHECKPOINT_INTERVAL = 25\n",
    "\n",
    "config = TropyAIConfig()\n",
    "\n",
    "# Configure models based on user selection from previous cell\n",
    "selected_provider = globals().get('selected_model_provider', 'gemini')\n",
    "\n",
    "if selected_provider == 'gemini':\n",
    "    config.GENERATIVE_MODEL = 'gemini-1.5-flash'\n",
    "    config.EMBEDDING_MODEL = 'models/embedding-001'\n",
    "elif selected_provider == 'openai':\n",
    "    config.GENERATIVE_MODEL = 'gpt-4o-mini'\n",
    "    config.EMBEDDING_MODEL = 'text-embedding-3-small'\n",
    "elif selected_provider == 'claude':\n",
    "    config.GENERATIVE_MODEL = 'claude-3-5-sonnet-20241022'\n",
    "    config.EMBEDDING_MODEL = None  # Claude doesn't have native embeddings\n",
    "else:\n",
    "    # Fallback to Gemini\n",
    "    config.GENERATIVE_MODEL = 'gemini-1.5-flash'\n",
    "    config.EMBEDDING_MODEL = 'models/embedding-001'\n",
    "\n",
    "print(f\"‚úÖ Configuration initialized for {config.GENERATIVE_MODEL}\")\n",
    "print(f\"   Embedding model: {config.EMBEDDING_MODEL or 'Not available'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-core",
   "metadata": {},
   "source": [
    "## 2. Core Processing Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "image-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Image Processing\n",
    "\n",
    "class ImageProcessor:\n",
    "    \"\"\"Handles image loading from Tropy API.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.session = requests.Session()\n",
    "        self.last_api_call_time = 0\n",
    "    \n",
    "    def _wait_for_api_delay(self):\n",
    "        \"\"\"Respect API rate limits.\"\"\"\n",
    "        current_time = time.time()\n",
    "        time_since_last_call = current_time - self.last_api_call_time\n",
    "        if time_since_last_call < self.config.API_IMAGE_DELAY:\n",
    "            sleep_time = self.config.API_IMAGE_DELAY - time_since_last_call\n",
    "            time.sleep(sleep_time)\n",
    "        self.last_api_call_time = time.time()\n",
    "    \n",
    "    def load_image_from_api(self, photo_id: int) -> Optional[Image.Image]:\n",
    "        \"\"\"Load image from Tropy API.\"\"\"\n",
    "        self._wait_for_api_delay()\n",
    "        image_url = f\"{self.config.TROPY_API_BASE}/project/photos/{photo_id}/file.jpg\"\n",
    "        \n",
    "        try:\n",
    "            response = self.session.get(image_url, timeout=self.config.IMAGE_TIMEOUT)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            \n",
    "            # Convert RGBA to RGB if needed\n",
    "            if image.mode == 'RGBA':\n",
    "                background = Image.new('RGB', image.size, (255, 255, 255))\n",
    "                background.paste(image, mask=image.split()[3])\n",
    "                image = background\n",
    "            elif image.mode not in ['RGB', 'L']:\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            return image\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to load image from API: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load_image(self, photo_data: Dict[str, Any]) -> Optional[Image.Image]:\n",
    "        \"\"\"Load image with local fallback.\"\"\"\n",
    "        photo_id = photo_data.get(\"id\")\n",
    "        image = self.load_image_from_api(photo_id)\n",
    "        \n",
    "        if not image:\n",
    "            # Try local path as fallback\n",
    "            local_path = photo_data.get(\"path\", \"\")\n",
    "            if local_path and os.path.exists(local_path):\n",
    "                try:\n",
    "                    image = Image.open(local_path)\n",
    "                    if image.mode == 'RGBA':\n",
    "                        background = Image.new('RGB', image.size, (255, 255, 255))\n",
    "                        background.paste(image, mask=image.split()[3])\n",
    "                        image = background\n",
    "                    return image\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to load from local path: {e}\")\n",
    "        \n",
    "        return image\n",
    "\n",
    "print(\"‚úÖ Image processor defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gemini-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Model Adapter Classes\n",
    "\n",
    "import time\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "def get_scholarly_analysis_prompt(transcription=\"\", context=None):\n",
    "    \"\"\"Generate the scholarly analysis prompt used across all model adapters.\"\"\"\n",
    "    context_str = \"\"\n",
    "    if context and len(context) > 0:\n",
    "        recent_context = context[-3:]  # Use rolling window of 3\n",
    "        context_str = \"\\n\\nContext from previous pages:\\n\" + \"\\n\".join(recent_context)\n",
    "    \n",
    "    return f\"\"\"\n",
    "You are a highly specialized historian and archival researcher analyzing an archival photo that may contain one or more document pages.\n",
    "\n",
    "- Primary source of textual content: Use the transcription text provided whenever available, prioritizing it for all factual and content descriptions.\n",
    "- Visual analysis: Use the image primarily to describe physical features (seals, stamps, layout, handwritten notes, overlays, partial folds, glued items, postcards) and overall structure.\n",
    "- Multiple parts: Be aware that a single image may include multiple overlapping documents or layers. Focus your description on the topmost active document, often marked by a visible folio number or placed upfront. Briefly mention secondary or underlying pages only when clearly visible and relevant.\n",
    "- Authenticity and physical features: Describe archival markers, seals, stamps, paper types, watermarks, or other signs of authenticity.\n",
    "- Transparency: If handwriting, language, or image quality limits your ability to extract text, explicitly state this rather than guessing or fabricating details.\n",
    "- Caution: Avoid inferring content not clearly visible or transcribed.\n",
    "- Languages: Whenever possible, indicate which language is being used across the document.\n",
    "\n",
    "**Context from previous pages (if any):**\n",
    "{context_str}\n",
    "\n",
    "**Your summary should:**\n",
    "- Be concise and scholarly (around 3‚Äì6 sentences).\n",
    "- Integrate textual and visual analysis smoothly in one narrative paragraph.\n",
    "- Clearly mention the document type, purpose, people, places, dates, and institutions when available.\n",
    "- Explicitly state if the transcription was used (e.g., \"Based on available transcription\") or if only partial text could be interpreted.\n",
    "\n",
    "Transcription (preferred source): {transcription or 'No transcription available.'}\n",
    "\n",
    "**Note: This summary is machine-generated and should be verified by a researcher.**\n",
    "\"\"\"\n",
    "\n",
    "def apply_rate_limit(last_api_call, rate_limit_delay):\n",
    "    \"\"\"Apply rate limiting between API calls.\"\"\"\n",
    "    current_time = time.time()\n",
    "    time_since_last = current_time - last_api_call\n",
    "    if time_since_last < rate_limit_delay:\n",
    "        sleep_time = rate_limit_delay - time_since_last\n",
    "        time.sleep(sleep_time)\n",
    "    return time.time()\n",
    "\n",
    "def image_to_base64(image):\n",
    "    \"\"\"Convert PIL image to base64 string.\"\"\"\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "class ModelAdapter:\n",
    "    \"\"\"Base adapter interface for all models\"\"\"\n",
    "    def generate_summary(self, image, transcription=\"\", context=None):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def generate_embedding(self, image, transcription=\"\"):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GeminiAdapter(ModelAdapter):\n",
    "    \"\"\"Adapter for Google Gemini\"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "            raise ValueError(\"Google API key not configured\")\n",
    "        import google.generativeai as genai\n",
    "        self.generative_model = genai.GenerativeModel(config.GENERATIVE_MODEL)\n",
    "        self.last_api_call = 0\n",
    "    \n",
    "    def generate_summary(self, image, transcription=\"\", context=None):\n",
    "        \"\"\"Generate scholarly summary of document page.\"\"\"\n",
    "        self.last_api_call = apply_rate_limit(self.last_api_call, self.config.RATE_LIMIT_DELAY)\n",
    "        \n",
    "        prompt = get_scholarly_analysis_prompt(transcription, context)\n",
    "        \n",
    "        try:\n",
    "            response = self.generative_model.generate_content([prompt, image])\n",
    "            return response.text if response else None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating summary: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_embedding(self, image, transcription=\"\"):\n",
    "        \"\"\"Generate embedding for semantic search.\"\"\"\n",
    "        self.last_api_call = apply_rate_limit(self.last_api_call, self.config.RATE_LIMIT_DELAY)\n",
    "        \n",
    "        visual_prompt = (\n",
    "            \"Describe this historical document image in detail. \"\n",
    "            \"Focus on layout, visual elements, text density, and document type.\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            import google.generativeai as genai\n",
    "            visual_response = self.generative_model.generate_content([visual_prompt, image])\n",
    "            if not visual_response:\n",
    "                return None\n",
    "            \n",
    "            combined_text = f\"Visual: {visual_response.text}\\nTranscription: {transcription or 'N/A'}\"\n",
    "            embedding_response = genai.embed_content(\n",
    "                model=self.config.EMBEDDING_MODEL, \n",
    "                content=combined_text\n",
    "            )\n",
    "            \n",
    "            return embedding_response.get('embedding') if embedding_response else None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating embedding: {e}\")\n",
    "            return None\n",
    "\n",
    "class OpenAIAdapter(ModelAdapter):\n",
    "    \"\"\"Adapter for OpenAI models\"\"\"\n",
    "    def __init__(self, config):\n",
    "        import openai\n",
    "        from openai import OpenAI\n",
    "        \n",
    "        self.client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.config = config\n",
    "        self.last_api_call = 0\n",
    "    \n",
    "    def generate_summary(self, image, transcription=\"\", context=None):\n",
    "        self.last_api_call = apply_rate_limit(self.last_api_call, self.config.RATE_LIMIT_DELAY)\n",
    "        \n",
    "        prompt = get_scholarly_analysis_prompt(transcription, context)\n",
    "        \n",
    "        try:\n",
    "            base64_image = image_to_base64(image)\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.config.GENERATIVE_MODEL,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": prompt},\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/png;base64,{base64_image}\",\n",
    "                                    \"detail\": \"high\"\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=500\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating summary with OpenAI: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_embedding(self, image, transcription=\"\"):\n",
    "        self.last_api_call = apply_rate_limit(self.last_api_call, self.config.RATE_LIMIT_DELAY)\n",
    "        \n",
    "        # First get visual description\n",
    "        visual_prompt = (\n",
    "            \"Describe this historical document image in detail. \"\n",
    "            \"Focus on layout, visual elements, text density, and document type.\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            base64_image = image_to_base64(image)\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.config.GENERATIVE_MODEL,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": visual_prompt},\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/png;base64,{base64_image}\",\n",
    "                                    \"detail\": \"low\"  # Lower detail for embedding\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=300\n",
    "            )\n",
    "            \n",
    "            visual_description = response.choices[0].message.content\n",
    "            \n",
    "            # Combine with transcription and generate embedding\n",
    "            combined_text = f\"Visual: {visual_description}\\nTranscription: {transcription or 'N/A'}\"\n",
    "            \n",
    "            embedding_response = self.client.embeddings.create(\n",
    "                model=self.config.EMBEDDING_MODEL,\n",
    "                input=combined_text[:8000]  # Limit length\n",
    "            )\n",
    "            \n",
    "            return embedding_response.data[0].embedding\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating embedding with OpenAI: {e}\")\n",
    "            return None\n",
    "\n",
    "class ClaudeAdapter(ModelAdapter):\n",
    "    \"\"\"Adapter for Anthropic Claude\"\"\"\n",
    "    def __init__(self, config):\n",
    "        import anthropic\n",
    "        \n",
    "        self.client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "        self.config = config\n",
    "        self.last_api_call = 0\n",
    "    \n",
    "    def generate_summary(self, image, transcription=\"\", context=None):\n",
    "        self.last_api_call = apply_rate_limit(self.last_api_call, self.config.RATE_LIMIT_DELAY)\n",
    "        \n",
    "        prompt = get_scholarly_analysis_prompt(transcription, context)\n",
    "        \n",
    "        try:\n",
    "            base64_image = image_to_base64(image)\n",
    "            \n",
    "            message = self.client.messages.create(\n",
    "                model=self.config.GENERATIVE_MODEL,\n",
    "                max_tokens=500,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": prompt\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image\",\n",
    "                                \"source\": {\n",
    "                                    \"type\": \"base64\",\n",
    "                                    \"media_type\": \"image/png\",\n",
    "                                    \"data\": base64_image\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            return message.content[0].text\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating summary with Claude: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_embedding(self, image, transcription=\"\"):\n",
    "        # Use OpenAI for embeddings since Claude doesn't provide them\n",
    "        self.last_api_call = apply_rate_limit(self.last_api_call, self.config.RATE_LIMIT_DELAY)\n",
    "        \n",
    "        try:\n",
    "            # Check if OpenAI is available\n",
    "            if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "                logger.info(\"No OpenAI key for embeddings - skipping\")\n",
    "                return None\n",
    "                \n",
    "            from openai import OpenAI\n",
    "            openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "            \n",
    "            # First get visual description using Claude\n",
    "            visual_prompt = (\n",
    "                \"Describe this historical document image in detail. \"\n",
    "                \"Focus on layout, visual elements, text density, and document type.\"\n",
    "            )\n",
    "            \n",
    "            base64_image = image_to_base64(image)\n",
    "            \n",
    "            message = self.client.messages.create(\n",
    "                model=self.config.GENERATIVE_MODEL,\n",
    "                max_tokens=300,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": visual_prompt},\n",
    "                        {\n",
    "                            \"type\": \"image\",\n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\",\n",
    "                                \"media_type\": \"image/png\",\n",
    "                                \"data\": base64_image\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            visual_description = message.content[0].text\n",
    "            \n",
    "            # Combine with transcription and generate embedding using OpenAI\n",
    "            combined_text = f\"Visual: {visual_description}\\nTranscription: {transcription or 'N/A'}\"\n",
    "            \n",
    "            # Use hardcoded OpenAI embedding model since Claude doesn't do embeddings\n",
    "            embedding_response = openai_client.embeddings.create(\n",
    "                model=\"text-embedding-3-small\",\n",
    "                input=combined_text[:8000]  # Limit length\n",
    "            )\n",
    "            \n",
    "            return embedding_response.data[0].embedding\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating embedding: {e}\")\n",
    "            return None\n",
    "\n",
    "# Factory function to get the right adapter\n",
    "def get_model_adapter(config):\n",
    "    \"\"\"Returns the appropriate model adapter based on user selection\"\"\"\n",
    "    provider = globals().get('selected_model_provider', 'gemini')\n",
    "    \n",
    "    if provider == 'gemini':\n",
    "        return GeminiAdapter(config)\n",
    "    elif provider == 'openai':\n",
    "        return OpenAIAdapter(config)\n",
    "    elif provider == 'claude':\n",
    "        return ClaudeAdapter(config)\n",
    "    else:\n",
    "        # Default fallback\n",
    "        return GeminiAdapter(config)\n",
    "\n",
    "print(\"‚úÖ Model adapters configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropy-api-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Tropy API Integration\n",
    "\n",
    "class TropyAPIClient:\n",
    "    \"\"\"Handles all Tropy API interactions.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.session = requests.Session()\n",
    "        self.api_base = config.TROPY_API_BASE\n",
    "    \n",
    "    def fetch_all_items(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Fetch all items from Tropy.\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(f'{self.api_base}/project/items/')\n",
    "            response.raise_for_status()\n",
    "            items = response.json()\n",
    "            logger.info(f\"Fetched {len(items)} items\")\n",
    "            return items\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"Failed to fetch items: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def fetch_photo_details(self, photo_id: int) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Fetch photo metadata.\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(f'{self.api_base}/project/photos/{photo_id}')\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to fetch photo {photo_id}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def fetch_transcription_details(self, transcription_id: int) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Fetch transcription by ID.\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(f'{self.api_base}/project/transcriptions/{transcription_id}')\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to fetch transcription {transcription_id}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def save_note_to_photo(self, photo_id: int, note_text: str) -> bool:\n",
    "        \"\"\"Save note to photo.\"\"\"\n",
    "        try:\n",
    "            post_url = f\"{self.api_base}/project/notes\"\n",
    "            note_data = [('photo', photo_id), ('html', note_text)]\n",
    "            response = self.session.post(post_url, data=note_data)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Apply delay after successful save\n",
    "            time.sleep(self.config.API_NOTE_DELAY)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save note for photo {photo_id}: {e}\")\n",
    "            return False\n",
    "\n",
    "def extract_transcription(photo_data: Dict[str, Any], api_client: TropyAPIClient) -> str:\n",
    "    \"\"\"Extract transcription text from photo data.\"\"\"\n",
    "    transcription_text = \"\"\n",
    "    transcriptions = photo_data.get('transcriptions', [])\n",
    "    \n",
    "    if transcriptions and isinstance(transcriptions, list) and len(transcriptions) > 0:\n",
    "        transcription_id = transcriptions[0]\n",
    "        try:\n",
    "            transcription_data = api_client.fetch_transcription_details(transcription_id)\n",
    "            if transcription_data:\n",
    "                transcription_text = transcription_data.get('text', '')\n",
    "                if transcription_text is None:\n",
    "                    transcription_text = \"\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to fetch transcription {transcription_id}: {e}\")\n",
    "    \n",
    "    return transcription_text.strip()\n",
    "\n",
    "print(\"‚úÖ Tropy API client defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initialize-processors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Initialize All Processors\n",
    "\n",
    "api_client = TropyAPIClient(config)\n",
    "image_processor = ImageProcessor(config)\n",
    "model_processor = get_model_adapter(config) \n",
    "\n",
    "print(f\"‚úÖ All processors initialized with {globals().get('selected_model_provider', 'gemini')} model\")\n",
    "\n",
    "print(\"‚úÖ All processors initialized and ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-selection",
   "metadata": {},
   "source": [
    "## 3. Item Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "item-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Select Items to Process\n",
    "\n",
    "# Fetch all items\n",
    "all_items_data = api_client.fetch_all_items()\n",
    "\n",
    "if not all_items_data:\n",
    "    print(\"‚ùå No items found. Please check Tropy connection.\")\n",
    "    items_to_process = []\n",
    "    selected_item_ids = []  # Track selection even if empty\n",
    "else:\n",
    "    print(f\"üìö Found {len(all_items_data)} total items in Tropy\\n\")\n",
    "    \n",
    "    print(\"üéØ Select processing mode:\")\n",
    "    print(\"A. All items - Process entire project\")\n",
    "    print(\"B. Single item - Process specific item(s)\")\n",
    "    print(\"C. List - Process items in specific list(s)\")\n",
    "    print(\"\\nExamples: A, B 123, C 1,3\")\n",
    "    \n",
    "    mode_input = input(\"\\nYour choice: \").strip().upper()\n",
    "    \n",
    "    if not mode_input:\n",
    "        mode_input = \"C 1\"  # Default\n",
    "    \n",
    "    # Parse input\n",
    "    parts = mode_input.split()\n",
    "    choice = parts[0]\n",
    "    ids = []\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        id_string = ' '.join(parts[1:])\n",
    "        ids = [id.strip() for id in id_string.split(',') if id.strip()]\n",
    "    \n",
    "    items_to_process = []\n",
    "    selected_item_ids = []  \n",
    "    \n",
    "    if choice == 'A':\n",
    "        items_to_process = all_items_data\n",
    "        selected_item_ids = [item['id'] for item in items_to_process] \n",
    "        print(f\"\\n‚úÖ Selected ALL items ({len(items_to_process)} items)\")\n",
    "    \n",
    "    elif choice == 'B':\n",
    "        if ids:\n",
    "            for item_id in ids:\n",
    "                for item in all_items_data:\n",
    "                    if str(item.get('id')) == str(item_id):\n",
    "                        items_to_process.append(item)\n",
    "                        selected_item_ids.append(item['id']) \n",
    "                        print(f\"‚úì Found item {item_id}: {item.get('title', 'Untitled')}\")\n",
    "                        break\n",
    "    \n",
    "    elif choice == 'C':\n",
    "        if ids:\n",
    "            items_set = set()\n",
    "            for list_id in ids:\n",
    "                list_id_int = int(list_id)\n",
    "                list_items = [item for item in all_items_data \n",
    "                             if list_id_int in item.get('lists', [])]\n",
    "                if list_items:\n",
    "                    print(f\"‚úì List {list_id}: {len(list_items)} items\")\n",
    "                    for item in list_items:\n",
    "                        if item['id'] not in items_set:\n",
    "                            items_set.add(item['id'])\n",
    "                            items_to_process.append(item)\n",
    "                            selected_item_ids.append(item['id'])  \n",
    "        else:\n",
    "            # Default to list 1\n",
    "            items_to_process = [item for item in all_items_data \n",
    "                               if 1 in item.get('lists', [])]\n",
    "            selected_item_ids = [item['id'] for item in items_to_process]  \n",
    "    \n",
    "    # Store selection info globally for use in other cells\n",
    "    globals()['current_selection'] = {\n",
    "        'mode': choice,\n",
    "        'ids': ids,\n",
    "        'item_ids': selected_item_ids,\n",
    "        'items': items_to_process\n",
    "    }\n",
    "    \n",
    "    # Summary\n",
    "    if items_to_process:\n",
    "        total_photos = sum(len(item.get('photos', [])) for item in items_to_process)\n",
    "        print(f\"\\nüìä Summary:\")\n",
    "        print(f\"   Items: {len(items_to_process)}\")\n",
    "        print(f\"   Photos: {total_photos}\")\n",
    "        print(f\"\\nüíæ Selection stored for consistent processing throughout notebook\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collection-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Analyze Collection & Estimate Time (item selection-aware checkpoint)\n",
    "\n",
    "def estimate_processing_time(num_photos: int, seconds_per_photo: float = 15.0) -> Dict[str, Any]:\n",
    "    \"\"\"Estimate processing time with realistic values.\"\"\"\n",
    "    total_seconds = num_photos * seconds_per_photo\n",
    "    hours = int(total_seconds // 3600)\n",
    "    minutes = int((total_seconds % 3600) // 60)\n",
    "    seconds = int(total_seconds % 60)\n",
    "    \n",
    "    # Model-aware cost estimation\n",
    "    selected_provider = globals().get('selected_model_provider', 'gemini')\n",
    "    \n",
    "    # Approximate cost per photo for different models\n",
    "    cost_per_photo = {\n",
    "        'gemini': 0.001,      # Gemini Flash is very cheap\n",
    "        'openai': 0.003,      # GPT-4o-mini is inexpensive\n",
    "        'claude': 0.015       # Claude 3.5 Sonnet\n",
    "    }\n",
    "    \n",
    "    api_cost = num_photos * cost_per_photo.get(selected_provider, 0.001)\n",
    "    \n",
    "    return {\n",
    "        'total_seconds': total_seconds,\n",
    "        'formatted_time': f\"{hours}h {minutes}m {seconds}s\" if hours > 0 else f\"{minutes}m {seconds}s\",\n",
    "        'api_cost_estimate': api_cost,\n",
    "        'seconds_per_photo': seconds_per_photo\n",
    "    }\n",
    "\n",
    "if 'items_to_process' in locals() and items_to_process:\n",
    "    print(\"\\nüìä Analyzing Collection...\")\n",
    "    \n",
    "    # Get all photo IDs from selected items\n",
    "    selected_photo_ids = set()\n",
    "    for item in items_to_process:\n",
    "        selected_photo_ids.update(item.get('photos', []))\n",
    "    \n",
    "    total_photos = len(selected_photo_ids)\n",
    "    \n",
    "    # Check for existing checkpoint and count only relevant processed photos\n",
    "    already_processed_in_selection = 0\n",
    "    \n",
    "    if os.path.exists(config.CHECKPOINT_FILE):\n",
    "        try:\n",
    "            with open(config.CHECKPOINT_FILE, 'r') as f:\n",
    "                checkpoint_data = json.load(f)\n",
    "                checkpoint_photo_ids = set(checkpoint_data.get('processed_photo_ids', []))\n",
    "                \n",
    "                # Count only photos that are both in checkpoint AND in current selection\n",
    "                already_processed_in_selection = len(selected_photo_ids & checkpoint_photo_ids)\n",
    "                \n",
    "                if checkpoint_photo_ids:\n",
    "                    print(f\"\\nüìå Checkpoint found: {len(checkpoint_photo_ids)} total photos in checkpoint\")\n",
    "                    if already_processed_in_selection > 0:\n",
    "                        print(f\"   ‚úÖ {already_processed_in_selection} of your selected photos already processed\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    photos_to_process = total_photos - already_processed_in_selection\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Processing Estimates:\")\n",
    "    print(f\"   Photos in selection: {total_photos}\")\n",
    "    if already_processed_in_selection > 0:\n",
    "        print(f\"   Already processed: {already_processed_in_selection}\")\n",
    "    print(f\"   Photos to process: {photos_to_process}\")\n",
    "    \n",
    "    if photos_to_process > 0:\n",
    "        time_estimate = estimate_processing_time(photos_to_process)\n",
    "        print(f\"   Estimated time: {time_estimate['formatted_time']}\")\n",
    "        print(f\"   (~{time_estimate['seconds_per_photo']:.0f} seconds per photo)\")\n",
    "        print(f\"   Estimated cost: ~${time_estimate['api_cost_estimate']:.2f}\")\n",
    "        \n",
    "        print(\"\\nüí° Recommendations:\")\n",
    "        if photos_to_process <= 20:\n",
    "            print(\"   ‚ö° Small batch - should complete in a few minutes\")\n",
    "        elif photos_to_process <= 100:\n",
    "            print(\"   ‚òï Medium batch - good time for a coffee break\")\n",
    "        elif photos_to_process <= 500:\n",
    "            print(\"   üçΩÔ∏è  Large batch - consider running during lunch\")\n",
    "        else:\n",
    "            print(\"   üåô Very large batch - consider running overnight\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ All selected photos have already been processed!\")\n",
    "        print(\"   Run Cell 13 to add item summaries, or\")\n",
    "        print(\"   Select different items to process new photos\")\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è  Note: Actual time may vary based on:\")\n",
    "    print(\"   - Image complexity and size\")\n",
    "    print(\"   - Length of transcriptions\")\n",
    "    print(\"   - Network speed and API response times\")\n",
    "    print(\"   - System performance\")\n",
    "    \n",
    "    if photos_to_process > 0:\n",
    "        print(\"\\nüëâ Ready to process? Run the next cell to start!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-processing",
   "metadata": {},
   "source": [
    "## 4. Main Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processing-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Processing Functions and Classes\n",
    "\n",
    "class BatchProcessor:\n",
    "    \"\"\"Handles batch processing with checkpointing.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.checkpoint_data = self._load_checkpoint()\n",
    "    \n",
    "    def _load_checkpoint(self) -> Dict[str, Any]:\n",
    "        \"\"\"Load checkpoint if exists.\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(self.config.CHECKPOINT_FILE):\n",
    "                with open(self.config.CHECKPOINT_FILE, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                data['processed_photo_ids'] = set(data['processed_photo_ids'])\n",
    "                logger.info(f\"Loaded checkpoint: {len(data['processed_photo_ids'])} photos processed\")\n",
    "                return data\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not load checkpoint: {e}\")\n",
    "        \n",
    "        return {\n",
    "            'processed_photo_ids': set(),\n",
    "            'processed_photos': 0,\n",
    "            'last_update': None,\n",
    "            'embeddings_buffer': [],\n",
    "            'item_summaries_buffer': []\n",
    "        }\n",
    "    \n",
    "    def _save_checkpoint(self):\n",
    "        \"\"\"Save progress to checkpoint.\"\"\"\n",
    "        try:\n",
    "            checkpoint = {\n",
    "                'processed_photo_ids': list(self.checkpoint_data['processed_photo_ids']),\n",
    "                'processed_photos': self.checkpoint_data['processed_photos'],\n",
    "                'last_update': datetime.now().isoformat(),\n",
    "                'embeddings_buffer': self.checkpoint_data['embeddings_buffer'],\n",
    "                'item_summaries_buffer': self.checkpoint_data['item_summaries_buffer']\n",
    "            }\n",
    "            with open(self.config.CHECKPOINT_FILE, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save checkpoint: {e}\")\n",
    "    \n",
    "    def _save_embeddings_batch(self, force: bool = False):\n",
    "        \"\"\"Save embeddings buffer to file.\"\"\"\n",
    "        if not self.checkpoint_data['embeddings_buffer']:\n",
    "            return\n",
    "        \n",
    "        if force or len(self.checkpoint_data['embeddings_buffer']) >= self.config.BATCH_SIZE:\n",
    "            try:\n",
    "                combined_data = {'photo_embeddings': [], 'item_summaries': []}\n",
    "                if os.path.exists(self.config.EMBEDDINGS_FILE):\n",
    "                    with open(self.config.EMBEDDINGS_FILE, 'r') as f:\n",
    "                        existing_data = json.load(f)\n",
    "                        if isinstance(existing_data, list):\n",
    "                            combined_data['photo_embeddings'] = existing_data\n",
    "                        else:\n",
    "                            combined_data = existing_data\n",
    "                \n",
    "                combined_data['photo_embeddings'].extend(self.checkpoint_data['embeddings_buffer'])\n",
    "                \n",
    "                with open(self.config.EMBEDDINGS_FILE, 'w') as f:\n",
    "                    json.dump(combined_data, f, indent=2)\n",
    "                \n",
    "                logger.info(f\"Saved {len(self.checkpoint_data['embeddings_buffer'])} embeddings\")\n",
    "                self.checkpoint_data['embeddings_buffer'] = []\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to save embeddings: {e}\")\n",
    "\n",
    "def generate_item_summary(item_title: str, photo_summaries: List[Dict[str, Any]], \n",
    "                         context_str: str = \"\") -> Optional[str]:\n",
    "    \"\"\"Generate a comprehensive summary for the entire item.\"\"\"\n",
    "    if not photo_summaries:\n",
    "        return None\n",
    "    \n",
    "    # Compile all photo summaries\n",
    "    all_summaries = []\n",
    "    for ps in photo_summaries:\n",
    "        summary_text = f\"Page {ps.get('page', 0)}: {ps.get('summary', '')}\"\n",
    "        all_summaries.append(summary_text)\n",
    "    \n",
    "    combined_summaries = \"\\n\".join(all_summaries)\n",
    "    \n",
    "    # The historian prompt for item summaries\n",
    "    prompt = f\"\"\"\n",
    "    You are a highly specialized historian and archival researcher. You have access to the following photo summaries. Your task is to synthesize a comprehensive, scholarly-level overall summary of this archival item.\n",
    "    \n",
    "    A clear suggested title for the item at the beginning (write \"Suggested title: ...\" explicitly in the first line).\n",
    "    \n",
    "    For the Suggested title, prioritize specificity over generality whenever possible:\n",
    "    - The title must include, if identifiable:\n",
    "      1. The specific person or family name.\n",
    "      2. The type of request or situation (e.g., visa, baptism, financial aid, employment reinstatement).\n",
    "      3. Brief historical context (e.g., date range, relevant laws, locations).\n",
    "    - If no individual or family is clearly identifiable, provide a concise descriptive title summarizing the main content.\n",
    "    - Avoid generic collection-level titles that repeat provenance information already known.\n",
    "    \n",
    "    Then, in your summary, describe:\n",
    "    - What the document is and its general purpose.\n",
    "    - The institutions or departments involved.\n",
    "    - Historical context and relevant dates.\n",
    "    - Physical or archival structure (pages, folders, seals, stamps).\n",
    "    - Main content and themes (cases, people, humanitarian aspects).\n",
    "    - Any key individuals or cases if identifiable.\n",
    "    - Why this item is historically significant.\n",
    "    - Evidence of authenticity (stamps, handwriting, watermarks, archival features).\n",
    "    \n",
    "    Instructions:\n",
    "    \n",
    "    Integrate information smoothly rather than listing separate headings.\n",
    "    Use the photo summaries as your main evidence.\n",
    "    Be transparent if some information is unclear or missing.\n",
    "    Do not fabricate or guess beyond provided photo summaries.\n",
    "    \n",
    "    Context from previous pages (if any):\n",
    "    {context_str}\n",
    "    \n",
    "    **Note: This summary is machine-generated and should be reviewed by a researcher.**\n",
    "    \n",
    "    Current item title: {item_title}\n",
    "    \n",
    "    Photo summaries:\n",
    "    {combined_summaries}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Get the selected provider\n",
    "        provider = globals().get('selected_model_provider', 'gemini')\n",
    "        \n",
    "        if provider == 'gemini':\n",
    "            import google.generativeai as genai\n",
    "            model = genai.GenerativeModel(config.GENERATIVE_MODEL)\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text if response else None\n",
    "            \n",
    "        elif provider == 'openai':\n",
    "            from openai import OpenAI\n",
    "            client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "            response = client.chat.completions.create(\n",
    "                model=config.GENERATIVE_MODEL,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=1000\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        elif provider == 'claude':\n",
    "            import anthropic\n",
    "            client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "            message = client.messages.create(\n",
    "                model=config.GENERATIVE_MODEL,\n",
    "                max_tokens=1000,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            return message.content[0].text\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate item summary: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_current_run_summaries(summaries: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"Save summaries for current run to a separate timestamped file.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "        \n",
    "        # Create timestamped filename\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"item_summaries_run_{timestamp}.json\"\n",
    "        filepath = os.path.join(config.OUTPUT_DIR, filename)\n",
    "        \n",
    "        # Save summaries\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(summaries, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Saved {len(summaries)} summaries to {filepath}\")\n",
    "        return filepath\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save current run summaries: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_item_summaries(summaries: List[Dict[str, Any]], append_to_main: bool = True) -> None:\n",
    "    \"\"\"Save item summaries to JSON file.\"\"\"\n",
    "    try:\n",
    "        output_file = os.path.join(config.OUTPUT_DIR, \"item_summaries.json\")\n",
    "        os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "        \n",
    "        if append_to_main:\n",
    "            # Original behavior - append to main file\n",
    "            existing_summaries = []\n",
    "            if os.path.exists(output_file):\n",
    "                with open(output_file, 'r') as f:\n",
    "                    existing_summaries = json.load(f)\n",
    "            \n",
    "            existing_summaries.extend(summaries)\n",
    "            \n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(existing_summaries, f, indent=2)\n",
    "            \n",
    "            logger.info(f\"Saved {len(summaries)} item summaries to {output_file}\")\n",
    "        \n",
    "        # Always save current run separately\n",
    "        current_run_file = save_current_run_summaries(summaries)\n",
    "        \n",
    "        # Store current run file path globally\n",
    "        globals()['current_run_summaries_file'] = current_run_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save item summaries: {e}\")\n",
    "\n",
    "print(\"‚úÖ Processing functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Main Processing Loop\n",
    "\n",
    "def process_collection(processor, items, generate_summaries=True, \n",
    "                      generate_embeddings=True, generate_item_summaries=True):\n",
    "    \"\"\"Process items with progress tracking.\"\"\"\n",
    "    \n",
    "    results = {\n",
    "        'processed_photos': 0,\n",
    "        'summaries_created': 0,\n",
    "        'embeddings_created': 0,\n",
    "        'item_summaries_created': 0,\n",
    "        'errors': 0\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Count total photos and photos that need processing\n",
    "    total_photos = sum(len(item.get('photos', [])) for item in items)\n",
    "    photos_to_process = 0\n",
    "    skipped_photos = 0\n",
    "    \n",
    "    # Count photos that will actually be processed (not in checkpoint)\n",
    "    for item in items:\n",
    "        for photo_id in item.get('photos', []):\n",
    "            if photo_id not in processor.checkpoint_data['processed_photo_ids']:\n",
    "                photos_to_process += 1\n",
    "            else:\n",
    "                skipped_photos += 1\n",
    "    \n",
    "    print(f\"\\nüöÄ Starting processing for {len(items)} items...\")\n",
    "    print(f\"   Total photos in selection: {total_photos}\")\n",
    "    if skipped_photos > 0:\n",
    "        print(f\"   Already processed (skipping): {skipped_photos}\")\n",
    "    print(f\"   Photos to process: {photos_to_process}\")\n",
    "    print(\"üõ°Ô∏è  Checkpointing enabled - safe to interrupt\\n\")\n",
    "    \n",
    "    # Use photos_to_process for progress bar instead of total_photos\n",
    "    with tqdm(total=photos_to_process, desc=\"Processing new photos\", unit=\"photo\") as pbar:\n",
    "        # Don't update for already processed photos\n",
    "        \n",
    "        for item in items:\n",
    "            item_id = item.get('id')\n",
    "            item_title = item.get('title', 'Untitled')\n",
    "            photo_ids = item.get('photos', [])\n",
    "            item_photo_summaries = []\n",
    "            \n",
    "            for photo_id in photo_ids:\n",
    "                try:\n",
    "                    # Skip if already processed (don't update progress bar)\n",
    "                    if photo_id in processor.checkpoint_data['processed_photo_ids']:\n",
    "                        continue\n",
    "                    \n",
    "                    # Fetch photo data\n",
    "                    photo_data = api_client.fetch_photo_details(photo_id)\n",
    "                    if not photo_data:\n",
    "                        results['errors'] += 1\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "                    \n",
    "                    # Load image\n",
    "                    image = image_processor.load_image(photo_data)\n",
    "                    if not image:\n",
    "                        results['errors'] += 1\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract transcription\n",
    "                    transcription = extract_transcription(photo_data, api_client)\n",
    "                    \n",
    "                    # Generate summary\n",
    "                    summary_text = \"\"\n",
    "                    if generate_summaries:\n",
    "                        summary = model_processor.generate_summary(image, transcription)\n",
    "                        if summary:\n",
    "                            # Format and save note\n",
    "                            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "                            header = (\n",
    "                                f\"<div style='background-color: #f9f9f9; padding: 10px; margin-bottom: 10px;'>\"\n",
    "                                f\"<strong>ü§ñ Machine-generated photo summary</strong><br/>\"\n",
    "                                f\"<small>Generated on {timestamp} by {config.GENERATIVE_MODEL}</small>\"\n",
    "                            )\n",
    "                            if transcription:\n",
    "                                header += \"<br/><small>‚úÖ Used transcription data</small>\"\n",
    "                            header += \"</div>\"\n",
    "                            \n",
    "                            formatted_summary = f\"{header}<p>{summary}</p>\"\n",
    "                            \n",
    "                            if api_client.save_note_to_photo(photo_id, formatted_summary):\n",
    "                                results['summaries_created'] += 1\n",
    "                                summary_text = summary\n",
    "                                item_photo_summaries.append({\n",
    "                                    'photo_id': photo_id,\n",
    "                                    'summary': summary,\n",
    "                                    'filename': photo_data.get('filename', ''),\n",
    "                                    'page': photo_data.get('page', 0),\n",
    "                                    'transcription': transcription[:500] if transcription else \"\"\n",
    "                                })\n",
    "                    \n",
    "                    # Generate embedding\n",
    "                    if generate_embeddings:\n",
    "                        embedding = model_processor.generate_embedding(image, transcription)\n",
    "                        if embedding:\n",
    "                            processor.checkpoint_data['embeddings_buffer'].append({\n",
    "                                'item_id': item_id,\n",
    "                                'photo_id': photo_id,\n",
    "                                'item_title': item_title,\n",
    "                                'embedding': embedding,\n",
    "                                'summary': summary_text,\n",
    "                                'timestamp': datetime.now().isoformat()\n",
    "                            })\n",
    "                            results['embeddings_created'] += 1\n",
    "                            processor._save_embeddings_batch()\n",
    "                    \n",
    "                    # Update checkpoint\n",
    "                    processor.checkpoint_data['processed_photo_ids'].add(photo_id)\n",
    "                    processor.checkpoint_data['processed_photos'] += 1\n",
    "                    results['processed_photos'] += 1\n",
    "                    \n",
    "                    if processor.checkpoint_data['processed_photos'] % processor.config.CHECKPOINT_INTERVAL == 0:\n",
    "                        processor._save_checkpoint()\n",
    "                    \n",
    "                    del image  # Free memory\n",
    "                    \n",
    "                except KeyboardInterrupt:\n",
    "                    logger.info(\"Interrupted - saving progress...\")\n",
    "                    processor._save_checkpoint()\n",
    "                    processor._save_embeddings_batch(force=True)\n",
    "                    raise\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing photo {photo_id}: {e}\")\n",
    "                    results['errors'] += 1\n",
    "                finally:\n",
    "                    pbar.update(1)\n",
    "            \n",
    "            # Generate item summary if needed\n",
    "            if generate_item_summaries and item_photo_summaries:\n",
    "                try:\n",
    "                    item_summary = generate_item_summary(item_title, item_photo_summaries)\n",
    "                    \n",
    "                    if item_summary:\n",
    "                        # Extract suggested title from the first line\n",
    "                        lines = item_summary.split(\"\\n\")\n",
    "                        suggested_title = \"\"\n",
    "                        for line in lines:\n",
    "                            if line.strip().lower().startswith(\"suggested title:\"):\n",
    "                                suggested_title = line.replace(\"Suggested title:\", \"\").replace(\"suggested title:\", \"\").strip()\n",
    "                                break\n",
    "                        \n",
    "                        # Add to buffer for saving\n",
    "                        processor.checkpoint_data['item_summaries_buffer'].append({\n",
    "                            'item_id': item_id,\n",
    "                            'item_title': item_title,\n",
    "                            'photo_count': len(photo_ids),\n",
    "                            'item_summary': item_summary,\n",
    "                            'suggested_title': suggested_title,\n",
    "                            'timestamp': datetime.now().isoformat(),\n",
    "                            'model': config.GENERATIVE_MODEL\n",
    "                        })\n",
    "                        results['item_summaries_created'] += 1\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed to generate item summary for {item_title}: {e}\")\n",
    "    \n",
    "    # Final save\n",
    "    processor._save_checkpoint()\n",
    "    processor._save_embeddings_batch(force=True)\n",
    "    \n",
    "    # Save item summaries if any\n",
    "    if processor.checkpoint_data['item_summaries_buffer']:\n",
    "        save_item_summaries(processor.checkpoint_data['item_summaries_buffer'])\n",
    "    \n",
    "    # Results summary\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # Calculate actual processing rate\n",
    "    if results['processed_photos'] > 0:\n",
    "        seconds_per_photo = elapsed / results['processed_photos']\n",
    "        print(f\"\\n‚úÖ Processing completed!\")\n",
    "        print(f\"   Photos processed: {results['processed_photos']}\")\n",
    "        print(f\"   Photos skipped: {skipped_photos}\")\n",
    "        print(f\"   Summaries created: {results['summaries_created']}\")\n",
    "        print(f\"   Item summaries: {results['item_summaries_created']}\")\n",
    "        print(f\"   Embeddings created: {results['embeddings_created']}\")\n",
    "        print(f\"   Errors: {results['errors']}\")\n",
    "        print(f\"   Time: {elapsed/60:.1f} minutes\")\n",
    "        print(f\"   Speed: {seconds_per_photo:.1f} seconds/photo\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ No new photos to process!\")\n",
    "        print(f\"   All {total_photos} photos were already processed\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Main processing function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Execute Processing\n",
    "\n",
    "if 'items_to_process' in locals() and items_to_process:\n",
    "    # Create batch processor\n",
    "    batch_processor = BatchProcessor(config)\n",
    "    \n",
    "    # Run processing\n",
    "    results = process_collection(\n",
    "        batch_processor,\n",
    "        items_to_process,\n",
    "        generate_summaries=True,\n",
    "        generate_embeddings=True,\n",
    "        generate_item_summaries=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüí° Next steps:\")\n",
    "    print(\"   1. Run Cell 13 to add item summaries to Tropy\")\n",
    "    print(\"   2. Check your Tropy project for the new notes!\")\n",
    "else:\n",
    "    print(\"‚ùå No items selected. Please run item selection cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-post-processing",
   "metadata": {},
   "source": [
    "## 5. Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add-item-summaries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Add Item Summaries to Tropy (Selection-Aware)\n",
    "\n",
    "def add_item_summaries_to_tropy(use_current_run_only=True):\n",
    "    \"\"\"Read generated item summaries and add them as notes to items.\"\"\"\n",
    "    \n",
    "    print(\"üìö Adding item summaries to Tropy...\")\n",
    "    \n",
    "    # Determine which summaries to use\n",
    "    if use_current_run_only and 'current_run_summaries_file' in globals():\n",
    "        # Use only summaries from current run\n",
    "        summaries_file = globals()['current_run_summaries_file']\n",
    "        print(f\"‚úÖ Using current run summaries only\")\n",
    "    else:\n",
    "        # Use main summaries file\n",
    "        summaries_file = os.path.join(config.OUTPUT_DIR, \"item_summaries.json\")\n",
    "        print(f\"‚ö†Ô∏è  Using all summaries from main file\")\n",
    "    \n",
    "    # Check if summaries file exists\n",
    "    if not os.path.exists(summaries_file):\n",
    "        print(f\"‚ùå No summaries file found: {summaries_file}\")\n",
    "        return\n",
    "    \n",
    "    # Load the summaries\n",
    "    with open(summaries_file, 'r') as f:\n",
    "        all_summaries = json.load(f)\n",
    "    \n",
    "    # Filter summaries based on current selection if available\n",
    "    if 'current_selection' in globals() and use_current_run_only:\n",
    "        selected_item_ids = globals()['current_selection']['item_ids']\n",
    "        filtered_summaries = [s for s in all_summaries if s['item_id'] in selected_item_ids]\n",
    "        print(f\"‚úÖ Filtered to {len(filtered_summaries)} summaries matching current selection\")\n",
    "        print(f\"   Selection mode: {globals()['current_selection']['mode']}\")\n",
    "        if globals()['current_selection']['ids']:\n",
    "            print(f\"   Selected IDs: {', '.join(globals()['current_selection']['ids'])}\")\n",
    "        summaries_to_process = filtered_summaries\n",
    "    else:\n",
    "        summaries_to_process = all_summaries\n",
    "    \n",
    "    print(f\"\\nüìä Processing {len(summaries_to_process)} item summaries\")\n",
    "    \n",
    "    added_count = 0\n",
    "    skipped_count = 0\n",
    "    error_count = 0\n",
    "    replaced_count = 0\n",
    "    \n",
    "    # Process with progress bar\n",
    "    with tqdm(total=len(summaries_to_process), desc=\"Adding item summaries\", unit=\"item\") as pbar:\n",
    "        for summary_data in summaries_to_process:\n",
    "            item_id = summary_data['item_id']\n",
    "            item_title = summary_data.get('item_title', 'Untitled')\n",
    "            item_summary = summary_data.get('item_summary', '')\n",
    "            photo_count = summary_data.get('photo_count', 0)\n",
    "            suggested_title = summary_data.get('suggested_title', '')\n",
    "            \n",
    "            # Update progress bar description\n",
    "            pbar.set_description(f\"Processing: {item_title[:30]}...\")\n",
    "            \n",
    "            if not item_summary:\n",
    "                skipped_count += 1\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Get the item to find its photos\n",
    "                item_data = api_client.session.get(f\"{api_client.api_base}/project/items/{item_id}\").json()\n",
    "                photos = item_data.get('photos', [])\n",
    "                \n",
    "                if not photos:\n",
    "                    skipped_count += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # Use the FIRST photo to attach the item summary\n",
    "                first_photo_id = photos[0]\n",
    "                \n",
    "                # Check if this photo already has an item summary\n",
    "                photo_data = api_client.fetch_photo_details(first_photo_id)\n",
    "                if photo_data:\n",
    "                    notes = photo_data.get('notes', [])\n",
    "                    has_item_summary = False\n",
    "                    existing_note_id = None\n",
    "                    \n",
    "                    for note_id in notes:\n",
    "                        note_response = api_client.session.get(f\"{api_client.api_base}/project/notes/{note_id}\")\n",
    "                        if note_response.status_code == 200:\n",
    "                            note_data = note_response.json()\n",
    "                            note_html = note_data.get('html', '')\n",
    "                            if 'Machine-generated overall item summary' in note_html:\n",
    "                                has_item_summary = True\n",
    "                                existing_note_id = note_id\n",
    "                                \n",
    "                                # Apply batch decision if set\n",
    "                                if globals().get('batch_replace_decision') == 'skip_all':\n",
    "                                    skipped_count += 1\n",
    "                                    pbar.update(1)\n",
    "                                    continue\n",
    "                                elif globals().get('batch_replace_decision') == 'replace_all':\n",
    "                                    # Delete existing note\n",
    "                                    delete_response = api_client.session.delete(\n",
    "                                        f\"{api_client.api_base}/project/notes/{existing_note_id}\"\n",
    "                                    )\n",
    "                                    if delete_response.status_code in [200, 204]:\n",
    "                                        has_item_summary = False\n",
    "                                        replaced_count += 1\n",
    "                                else:\n",
    "                                    # First time encountering existing summary - ask user\n",
    "                                    print(f\"\\n‚ö†Ô∏è  Item '{item_title}' already has a summary\")\n",
    "                                    print(\"   What would you like to do?\")\n",
    "                                    print(\"   1. Skip this item\")\n",
    "                                    print(\"   2. Replace with new summary\")\n",
    "                                    print(\"   3. Skip all existing (default)\")\n",
    "                                    print(\"   4. Replace all existing\")\n",
    "                                    \n",
    "                                    decision = input(\"   Choice (1-4) [3]: \").strip() or \"3\"\n",
    "                                    \n",
    "                                    if decision == \"4\":\n",
    "                                        globals()['batch_replace_decision'] = 'replace_all'\n",
    "                                        # Delete existing note\n",
    "                                        delete_response = api_client.session.delete(\n",
    "                                            f\"{api_client.api_base}/project/notes/{existing_note_id}\"\n",
    "                                        )\n",
    "                                        if delete_response.status_code in [200, 204]:\n",
    "                                            has_item_summary = False\n",
    "                                            replaced_count += 1\n",
    "                                    elif decision == \"3\":\n",
    "                                        globals()['batch_replace_decision'] = 'skip_all'\n",
    "                                        skipped_count += 1\n",
    "                                        pbar.update(1)\n",
    "                                        continue\n",
    "                                    elif decision == \"2\":\n",
    "                                        # Delete existing note for this item only\n",
    "                                        delete_response = api_client.session.delete(\n",
    "                                            f\"{api_client.api_base}/project/notes/{existing_note_id}\"\n",
    "                                        )\n",
    "                                        if delete_response.status_code in [200, 204]:\n",
    "                                            has_item_summary = False\n",
    "                                            replaced_count += 1\n",
    "                                    else:\n",
    "                                        skipped_count += 1\n",
    "                                        pbar.update(1)\n",
    "                                        continue\n",
    "                \n",
    "                if not has_item_summary:\n",
    "                    # Create the formatted item summary note\n",
    "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "                    \n",
    "                    # Gray border for item summaries\n",
    "                    item_summary_header = (\n",
    "                        \"<div style='background-color: #f5f5f5; padding: 12px; margin-bottom: 10px; \"\n",
    "                        \"border-left: 4px solid #999999;'>\"\n",
    "                        \"<strong>üìö Machine-generated overall item summary</strong><br/>\"\n",
    "                        f\"<small>Generated on {timestamp} by {config.GENERATIVE_MODEL}</small><br/>\"\n",
    "                        f\"<small>Based on {photo_count} photo summaries</small>\"\n",
    "                    )\n",
    "                    if suggested_title:\n",
    "                        item_summary_header += f\"<br/><small>üìù Suggested title: {suggested_title}</small>\"\n",
    "                    item_summary_header += \"</div>\"\n",
    "                    \n",
    "                    formatted_summary = f\"{item_summary_header}<p>{item_summary}</p>\"\n",
    "                    \n",
    "                    # Save the note to Tropy (to first photo)\n",
    "                    if api_client.save_note_to_photo(first_photo_id, formatted_summary):\n",
    "                        added_count += 1\n",
    "                    else:\n",
    "                        error_count += 1\n",
    "                        \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing item {item_id}: {e}\")\n",
    "                error_count += 1\n",
    "            finally:\n",
    "                pbar.update(1)\n",
    "    \n",
    "    # Clear batch decision for next run\n",
    "    if 'batch_replace_decision' in globals():\n",
    "        del globals()['batch_replace_decision']\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üìä ITEM SUMMARY ADDITION COMPLETE\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"‚úÖ Added: {added_count} new summaries\")\n",
    "    if replaced_count > 0:\n",
    "        print(f\"üîÑ Replaced: {replaced_count} existing summaries\")\n",
    "    print(f\"‚ö†Ô∏è  Skipped: {skipped_count}\")\n",
    "    print(f\"‚ùå Errors: {error_count}\")\n",
    "    print(f\"üìã Total processed: {len(summaries_to_process)}\")\n",
    "    \n",
    "    if added_count > 0 or replaced_count > 0:\n",
    "        print(f\"\\nüéâ Item summaries are attached to the FIRST photo of each item!\")\n",
    "\n",
    "# Interactive menu for adding summaries\n",
    "def add_summaries_menu():\n",
    "    \"\"\"Interactive menu for adding summaries with options.\"\"\"\n",
    "    print(\"\\nüìö Add Item Summaries to Tropy\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Show current context\n",
    "    if 'current_selection' in globals():\n",
    "        selection = globals()['current_selection']\n",
    "        print(f\"Current selection: {selection['mode']}\", end=\"\")\n",
    "        if selection['ids']:\n",
    "            print(f\" - IDs: {', '.join(selection['ids'])}\")\n",
    "        else:\n",
    "            print()\n",
    "        print(f\"Selected items: {len(selection['item_ids'])}\")\n",
    "    \n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"1. Add summaries for CURRENT RUN only (recommended)\")\n",
    "    print(\"2. Add summaries for ALL items in main file\")\n",
    "    print(\"3. View current run summary\")\n",
    "    print(\"4. Cancel\")\n",
    "    \n",
    "    choice = input(\"\\nYour choice (1-4) [1]: \").strip() or \"1\"\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        add_item_summaries_to_tropy(use_current_run_only=True)\n",
    "    elif choice == \"2\":\n",
    "        confirm = input(\"\\n‚ö†Ô∏è  This will process ALL summaries. Continue? (y/n) [n]: \").strip().lower()\n",
    "        if confirm == 'y':\n",
    "            add_item_summaries_to_tropy(use_current_run_only=False)\n",
    "    elif choice == \"3\":\n",
    "        if 'current_run_summaries_file' in globals():\n",
    "            print(f\"\\nCurrent run summaries saved to:\")\n",
    "            print(f\"  {globals()['current_run_summaries_file']}\")\n",
    "            \n",
    "            # Show summary count\n",
    "            with open(globals()['current_run_summaries_file'], 'r') as f:\n",
    "                summaries = json.load(f)\n",
    "            print(f\"  Contains: {len(summaries)} item summaries\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå No current run summaries found\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Cancelled\")\n",
    "\n",
    "# Run the menu\n",
    "add_summaries_menu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-utilities",
   "metadata": {},
   "source": [
    "## 6. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-slate-notes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Clean Slate - Remove AI Notes\n",
    "\n",
    "def get_note_content(note_id):\n",
    "    \"\"\"Extract note content from Tropy API response.\"\"\"\n",
    "    try:\n",
    "        response = api_client.session.get(f\"{api_client.api_base}/project/notes/{note_id}\")\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "        \n",
    "        note_data = response.json()\n",
    "        \n",
    "        # Handle different response structures\n",
    "        if isinstance(note_data, dict):\n",
    "            # Check for html field\n",
    "            if 'html' in note_data:\n",
    "                if isinstance(note_data['html'], dict) and '@value' in note_data['html']:\n",
    "                    return note_data['html']['@value']\n",
    "                else:\n",
    "                    return str(note_data['html'])\n",
    "            # Check for text field\n",
    "            elif 'text' in note_data:\n",
    "                if isinstance(note_data['text'], dict) and '@value' in note_data['text']:\n",
    "                    return note_data['text']['@value']\n",
    "                else:\n",
    "                    return str(note_data['text'])\n",
    "        \n",
    "        return str(note_data)\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Error getting note content: {e}\")\n",
    "        return None\n",
    "\n",
    "def is_ai_generated(note_text):\n",
    "    \"\"\"Check if a note is AI-generated.\"\"\"\n",
    "    if not note_text:\n",
    "        return False\n",
    "    \n",
    "    ai_patterns = [\n",
    "        'Machine-generated photo summary',\n",
    "        'Machine-generated overall item summary',\n",
    "        'ü§ñ Machine-generated photo summary',\n",
    "        'üìö Machine-generated overall item summary',\n",
    "        'Generated on 2025-',\n",
    "        'Generated on 2024-',\n",
    "        'by gemini-1.5-flash',\n",
    "        'ai-generated',\n",
    "        'auto-generated',\n",
    "        'automatically generated',\n",
    "        'claude',\n",
    "        'chatgpt',\n",
    "        'gpt-'\n",
    "    ]\n",
    "    \n",
    "    note_lower = note_text.lower()\n",
    "    return any(pattern.lower() in note_lower for pattern in ai_patterns)\n",
    "\n",
    "def delete_note_multiple_methods(note_id):\n",
    "    \"\"\"Try multiple methods to delete a note.\"\"\"\n",
    "    # Try different endpoints and methods\n",
    "    endpoints_to_try = [\n",
    "        ('DELETE', f'{api_client.api_base}/project/notes/{note_id}'),\n",
    "        ('DELETE', f'{api_client.api_base}/notes/{note_id}'),\n",
    "        ('POST', f'{api_client.api_base}/project/notes/{note_id}/delete'),\n",
    "        ('POST', f'{api_client.api_base}/project/notes/{note_id}', {'action': 'delete'}),\n",
    "        ('PUT', f'{api_client.api_base}/project/notes/{note_id}', {'html': '', 'deleted': True}),\n",
    "    ]\n",
    "    \n",
    "    for method_info in endpoints_to_try:\n",
    "        method = method_info[0]\n",
    "        url = method_info[1]\n",
    "        data = method_info[2] if len(method_info) > 2 else None\n",
    "        \n",
    "        try:\n",
    "            if method == 'DELETE':\n",
    "                res = api_client.session.delete(url)\n",
    "            elif method == 'POST':\n",
    "                res = api_client.session.post(url, data=data)\n",
    "            elif method == 'PUT':\n",
    "                res = api_client.session.put(url, json=data)\n",
    "            \n",
    "            if res.status_code in [200, 204, 404]:\n",
    "                return True\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Try one more method - empty the note\n",
    "    try:\n",
    "        empty_note_url = f'{api_client.api_base}/project/notes/{note_id}'\n",
    "        res = api_client.session.put(empty_note_url, data=[('html', '')])\n",
    "        if res.status_code in [200, 204]:\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return False\n",
    "\n",
    "def remove_ai_notes():\n",
    "    \"\"\"Remove AI-generated notes from Tropy.\"\"\"\n",
    "    \n",
    "    print(\"üßπ CLEAN SLATE - AI Notes Remover\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check connection\n",
    "    try:\n",
    "        test_response = api_client.session.get(f\"{api_client.api_base}/project/items/\")\n",
    "        if test_response.status_code != 200:\n",
    "            print(\"‚ùå Cannot connect to Tropy. Please check if Tropy is running with REST API enabled.\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Connection error: {e}\")\n",
    "        return\n",
    "    \n",
    "    print(\"‚úÖ Connected to Tropy successfully!\\n\")\n",
    "    \n",
    "    # Get all items\n",
    "    all_items = api_client.fetch_all_items()\n",
    "    if not all_items:\n",
    "        print(\"‚ùå No items found in Tropy.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìö Found {len(all_items)} items in Tropy\\n\")\n",
    "    \n",
    "    # Selection menu\n",
    "    print(\"Select what to clean:\")\n",
    "    print(\"A. All items - Remove AI notes from entire project\")\n",
    "    print(\"B. Single item - Remove from specific item(s)\")\n",
    "    print(\"C. List - Remove from specific list(s)\")\n",
    "    \n",
    "    choice_input = input(\"\\nYour choice: \").strip().upper()\n",
    "    \n",
    "    if not choice_input:\n",
    "        print(\"‚ùå No input provided. Cancelled.\")\n",
    "        return\n",
    "    \n",
    "    # Parse input\n",
    "    parts = choice_input.split()\n",
    "    choice = parts[0]\n",
    "    ids = []\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        id_string = ' '.join(parts[1:])\n",
    "        ids = [id.strip() for id in id_string.split(',') if id.strip()]\n",
    "    \n",
    "    # Determine which items to process\n",
    "    items_to_clean = []\n",
    "    \n",
    "    if choice == 'A':\n",
    "        items_to_clean = all_items\n",
    "        print(f\"\\n‚ö†Ô∏è  This will scan ALL {len(items_to_clean)} items for AI notes.\")\n",
    "        \n",
    "    elif choice == 'B':\n",
    "        if ids:\n",
    "            for item_id in ids:\n",
    "                for item in all_items:\n",
    "                    if str(item.get('id')) == str(item_id):\n",
    "                        items_to_clean.append(item)\n",
    "                        print(f\"‚úì Found item {item_id}: {item.get('title', 'Untitled')}\")\n",
    "                        break\n",
    "        else:\n",
    "            print(\"‚ùå No item IDs provided.\")\n",
    "            return\n",
    "            \n",
    "    elif choice == 'C':\n",
    "        if ids:\n",
    "            items_set = set()\n",
    "            for list_id in ids:\n",
    "                list_id_int = int(list_id)\n",
    "                list_items = [item for item in all_items \n",
    "                             if list_id_int in item.get('lists', [])]\n",
    "                if list_items:\n",
    "                    print(f\"‚úì List {list_id}: {len(list_items)} items\")\n",
    "                    for item in list_items:\n",
    "                        if item['id'] not in items_set:\n",
    "                            items_set.add(item['id'])\n",
    "                            items_to_clean.append(item)\n",
    "        else:\n",
    "            print(\"‚ùå No list IDs provided.\")\n",
    "            return\n",
    "    else:\n",
    "        print(\"‚ùå Invalid choice.\")\n",
    "        return\n",
    "    \n",
    "    if not items_to_clean:\n",
    "        print(\"\\n‚ùå No items selected for cleaning.\")\n",
    "        return\n",
    "    \n",
    "    # Scan for AI notes\n",
    "    print(f\"\\nüîç Scanning {len(items_to_clean)} items for AI-generated notes...\")\n",
    "    \n",
    "    ai_notes_found = []\n",
    "    total_photos_scanned = 0\n",
    "    \n",
    "    for item in tqdm(items_to_clean, desc=\"Scanning items\"):\n",
    "        item_id = item.get('id')\n",
    "        photos = item.get('photos', [])\n",
    "        \n",
    "        for photo_id in photos:\n",
    "            total_photos_scanned += 1\n",
    "            \n",
    "            try:\n",
    "                # Get photo details\n",
    "                photo_data = api_client.fetch_photo_details(photo_id)\n",
    "                if not photo_data:\n",
    "                    continue\n",
    "                \n",
    "                # Check each note\n",
    "                notes = photo_data.get('notes', [])\n",
    "                for note_id in notes:\n",
    "                    # Get note content with proper extraction\n",
    "                    note_text = get_note_content(note_id)\n",
    "                    \n",
    "                    if note_text and is_ai_generated(note_text):\n",
    "                        ai_notes_found.append({\n",
    "                            'note_id': note_id,\n",
    "                            'photo_id': photo_id,\n",
    "                            'item_id': item_id,\n",
    "                            'item_title': item.get('title', 'Untitled'),\n",
    "                            'is_item_summary': 'overall item summary' in note_text.lower()\n",
    "                        })\n",
    "                        \n",
    "            except Exception as e:\n",
    "                logger.debug(f\"Error checking photo {photo_id}: {e}\")\n",
    "    \n",
    "    print(f\"\\nüìä Scan complete:\")\n",
    "    print(f\"   Photos scanned: {total_photos_scanned}\")\n",
    "    print(f\"   AI notes found: {len(ai_notes_found)}\")\n",
    "    \n",
    "    if not ai_notes_found:\n",
    "        print(\"\\n‚ú® No AI-generated notes found! Nothing to clean.\")\n",
    "        return\n",
    "    \n",
    "    # Show summary by type\n",
    "    photo_summaries = [n for n in ai_notes_found if not n['is_item_summary']]\n",
    "    item_summaries = [n for n in ai_notes_found if n['is_item_summary']]\n",
    "    \n",
    "    print(f\"\\nüìù Found:\")\n",
    "    print(f\"   Photo summaries: {len(photo_summaries)}\")\n",
    "    print(f\"   Item summaries: {len(item_summaries)}\")\n",
    "    \n",
    "    # Show a few examples\n",
    "    print(\"\\nüìã Examples of notes found:\")\n",
    "    for i, note in enumerate(ai_notes_found[:3]):\n",
    "        note_type = \"Item summary\" if note['is_item_summary'] else \"Photo summary\"\n",
    "        print(f\"   {i+1}. {note_type} in '{note['item_title']}'\")\n",
    "    if len(ai_notes_found) > 3:\n",
    "        print(f\"   ... and {len(ai_notes_found) - 3} more\")\n",
    "    \n",
    "    # Confirmation\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: This will permanently delete {len(ai_notes_found)} notes!\")\n",
    "    confirm = input(\"Proceed with deletion? (y/n): \").strip().lower()\n",
    "    \n",
    "    if confirm not in ['yes', 'y']:\n",
    "        print(\"\\n‚ùå Deletion cancelled. Your notes are safe.\")\n",
    "        return\n",
    "    \n",
    "    # Delete notes\n",
    "    print(f\"\\nüóëÔ∏è  Deleting {len(ai_notes_found)} AI notes...\")\n",
    "    \n",
    "    deleted_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    for note_info in tqdm(ai_notes_found, desc=\"Deleting notes\"):\n",
    "        note_id = note_info['note_id']\n",
    "        \n",
    "        if delete_note_multiple_methods(note_id):\n",
    "            deleted_count += 1\n",
    "        else:\n",
    "            failed_count += 1\n",
    "            logger.debug(f\"Failed to delete note {note_id}\")\n",
    "        \n",
    "        # Small delay to avoid overwhelming the API\n",
    "        if deleted_count % 50 == 0:\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    # Final summary\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üìä CLEAN SLATE COMPLETE\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"‚úÖ Successfully deleted: {deleted_count} notes\")\n",
    "    if failed_count > 0:\n",
    "        print(f\"‚ùå Failed to delete: {failed_count} notes\")\n",
    "    print(f\"‚è±Ô∏è  Total processed: {len(ai_notes_found)}\")\n",
    "    \n",
    "    if deleted_count > 0:\n",
    "        print(f\"\\nüßπ Your Tropy is now cleaner!\")\n",
    "        print(\"üí° You can now run the processing pipeline again if needed.\")\n",
    "\n",
    "# Run the function\n",
    "remove_ai_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Clean Files and Checkpoints \n",
    "\n",
    "import os\n",
    "\n",
    "# Delete checkpoint\n",
    "if os.path.exists(config.CHECKPOINT_FILE):\n",
    "    os.remove(config.CHECKPOINT_FILE)\n",
    "    print(f\"‚úÖ Deleted checkpoint file: {config.CHECKPOINT_FILE}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  No checkpoint file found: {config.CHECKPOINT_FILE}\")\n",
    "\n",
    "# Delete embeddings file\n",
    "if os.path.exists(config.EMBEDDINGS_FILE):\n",
    "    os.remove(config.EMBEDDINGS_FILE)\n",
    "    print(f\"‚úÖ Deleted embeddings file: {config.EMBEDDINGS_FILE}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  No embeddings file found: {config.EMBEDDINGS_FILE}\")\n",
    "\n",
    "# Delete item summaries file\n",
    "summaries_file = os.path.join(config.OUTPUT_DIR, \"item_summaries.json\")\n",
    "if os.path.exists(summaries_file):\n",
    "    os.remove(summaries_file)\n",
    "    print(f\"‚úÖ Deleted item summaries file: {summaries_file}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  No item summaries file found: {summaries_file}\")\n",
    "\n",
    "# Remove empty output directory if it exists\n",
    "if os.path.exists(config.OUTPUT_DIR) and not os.listdir(config.OUTPUT_DIR):\n",
    "    os.rmdir(config.OUTPUT_DIR)\n",
    "    print(f\"‚úÖ Removed empty output directory: {config.OUTPUT_DIR}\")\n",
    "\n",
    "print(\"\\nüßπ File cleanup complete!\")\n",
    "\n",
    "# Check if there are run history files\n",
    "import glob\n",
    "run_files = glob.glob(os.path.join(config.OUTPUT_DIR, \"item_summaries_run_*.json\")) if os.path.exists(config.OUTPUT_DIR) else []\n",
    "if run_files:\n",
    "    print(f\"\\nüìù Note: {len(run_files)} timestamped run history files are preserved in {config.OUTPUT_DIR}\")\n",
    "    print(\"   These files contain summaries from individual processing runs. We intentionally keep them as history/backups for each session. It can be useful to compare results across different runs.\")\n",
    "    print(\"   Delete them manually if you need a completely clean slate.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
