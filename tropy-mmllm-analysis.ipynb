{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-intro",
   "metadata": {},
   "source": [
    "# üìÑ Tropy API Multimodal Analysis & Summarization Notebook\n",
    "\n",
    "This notebook provides an integrated, step-by-step workflow for processing collections in Tropy using multimodal large language models (MMLMs).\n",
    "\n",
    "## üóÇÔ∏è What It Does\n",
    "\n",
    "- Uses Tropy‚Äôs local API to extract item and photo data\n",
    "- Loads transcriptions (when available) and image files\n",
    "- Generates high-quality **photo summaries**, favoring transcriptions for text and using image context supportively\n",
    "- Synthesizes **item-level summaries**, based on all photo summaries within each item\n",
    "- Creates **semantic embeddings** (optional), which can be used for advanced search and clustering\n",
    "- Saves all results back to Tropy as notes, plus outputs to local JSON files\n",
    "- Supports batch checkpointing and resume functionality\n",
    "\n",
    "## ‚ö° Inspired by\n",
    "\n",
    "This work adapts and extends concepts from Taylor Arnold and Lauren Tilton's [Explainable Search and Discovery of Visual Cultural Heritage Collections with Multimodal Large Language Models](https://2024.computational-humanities-research.org/papers/paper28/), tailored for the DH2025 workshop *Transcribing the Vatican Archives: Contextualization, Limits, and Opportunities*, facilitated by Anita Lucchesi and Sean Takats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-setup",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Required Libraries\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from pdf2image import convert_from_path\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import faiss\n",
    "from typing import Optional, List, Dict, Any\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ All dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "api-key-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configure Google API Key\n",
    "\n",
    "print(\"üîß Setting up Google API Key...\\n\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check if .env file exists\n",
    "if os.path.exists('.env'):\n",
    "    print(\"‚úÖ Found .env file\")\n",
    "else:\n",
    "    print(\"üìù Creating .env file...\")\n",
    "    api_key_input = input(\"Please paste your Google API key here: \").strip()\n",
    "    if api_key_input:\n",
    "        with open('.env', 'w') as f:\n",
    "            f.write(f\"GOOGLE_API_KEY={api_key_input}\\n\")\n",
    "        print(\"‚úÖ Created .env file\")\n",
    "        load_dotenv()\n",
    "\n",
    "# Configure Gemini\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if api_key:\n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"‚úÖ Gemini API configured\")\n",
    "    \n",
    "    # Test the API\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        response = model.generate_content(\"Say 'Hello Tropy' in exactly 2 words\")\n",
    "        print(f\"‚úÖ API test successful: {response.text.strip()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API test failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå No API key found. Please check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Configuration Settings\n",
    "\n",
    "class TropyAIConfig:\n",
    "    \"\"\"Central configuration for the Tropy AI workflow.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # API Settings\n",
    "        self.TROPY_API_BASE = 'http://localhost:2019'\n",
    "        self.GENERATIVE_MODEL = 'gemini-1.5-flash'\n",
    "        self.EMBEDDING_MODEL = 'models/embedding-001'\n",
    "        \n",
    "        # Rate Limits and Delays\n",
    "        self.API_IMAGE_DELAY = 1.5\n",
    "        self.API_NOTE_DELAY = 3.0\n",
    "        self.IMAGE_TIMEOUT = 30\n",
    "        self.RATE_LIMIT_DELAY = 2.0\n",
    "        self.ROLLING_WINDOW_SIZE = 3\n",
    "        \n",
    "        # File Management\n",
    "        self.CHECKPOINT_FILE = \"processing_checkpoint.json\"\n",
    "        self.OUTPUT_DIR = \"./output\"\n",
    "        self.EMBEDDINGS_FILE = \"tropy_embeddings.json\"\n",
    "        \n",
    "        # Batch Processing\n",
    "        self.BATCH_SIZE = 50\n",
    "        self.CHECKPOINT_INTERVAL = 25\n",
    "\n",
    "config = TropyAIConfig()\n",
    "print(\"‚úÖ Configuration initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-core",
   "metadata": {},
   "source": [
    "## 2. Core Processing Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "image-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Image Processing\n",
    "\n",
    "class ImageProcessor:\n",
    "    \"\"\"Handles image loading from Tropy API.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.session = requests.Session()\n",
    "        self.last_api_call_time = 0\n",
    "    \n",
    "    def _wait_for_api_delay(self):\n",
    "        \"\"\"Respect API rate limits.\"\"\"\n",
    "        current_time = time.time()\n",
    "        time_since_last_call = current_time - self.last_api_call_time\n",
    "        if time_since_last_call < self.config.API_IMAGE_DELAY:\n",
    "            sleep_time = self.config.API_IMAGE_DELAY - time_since_last_call\n",
    "            time.sleep(sleep_time)\n",
    "        self.last_api_call_time = time.time()\n",
    "    \n",
    "    def load_image_from_api(self, photo_id: int) -> Optional[Image.Image]:\n",
    "        \"\"\"Load image from Tropy API.\"\"\"\n",
    "        self._wait_for_api_delay()\n",
    "        image_url = f\"{self.config.TROPY_API_BASE}/project/photos/{photo_id}/file.jpg\"\n",
    "        \n",
    "        try:\n",
    "            response = self.session.get(image_url, timeout=self.config.IMAGE_TIMEOUT)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            \n",
    "            # Convert RGBA to RGB if needed\n",
    "            if image.mode == 'RGBA':\n",
    "                background = Image.new('RGB', image.size, (255, 255, 255))\n",
    "                background.paste(image, mask=image.split()[3])\n",
    "                image = background\n",
    "            elif image.mode not in ['RGB', 'L']:\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            return image\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to load image from API: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load_image(self, photo_data: Dict[str, Any]) -> Optional[Image.Image]:\n",
    "        \"\"\"Load image with local fallback.\"\"\"\n",
    "        photo_id = photo_data.get(\"id\")\n",
    "        image = self.load_image_from_api(photo_id)\n",
    "        \n",
    "        if not image:\n",
    "            # Try local path as fallback\n",
    "            local_path = photo_data.get(\"path\", \"\")\n",
    "            if local_path and os.path.exists(local_path):\n",
    "                try:\n",
    "                    image = Image.open(local_path)\n",
    "                    if image.mode == 'RGBA':\n",
    "                        background = Image.new('RGB', image.size, (255, 255, 255))\n",
    "                        background.paste(image, mask=image.split()[3])\n",
    "                        image = background\n",
    "                    return image\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to load from local path: {e}\")\n",
    "        \n",
    "        return image\n",
    "\n",
    "print(\"‚úÖ Image processor defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gemini-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Gemini AI Processing\n",
    "\n",
    "class GeminiProcessor:\n",
    "    \"\"\"Handles Gemini model interactions for summaries and embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "            raise ValueError(\"Google API key not configured\")\n",
    "        self.generative_model = genai.GenerativeModel(config.GENERATIVE_MODEL)\n",
    "        self.last_api_call = 0\n",
    "    \n",
    "    def _apply_rate_limit(self):\n",
    "        \"\"\"Apply rate limiting between API calls.\"\"\"\n",
    "        current_time = time.time()\n",
    "        time_since_last = current_time - self.last_api_call\n",
    "        if time_since_last < self.config.RATE_LIMIT_DELAY:\n",
    "            sleep_time = self.config.RATE_LIMIT_DELAY - time_since_last\n",
    "            time.sleep(sleep_time)\n",
    "        self.last_api_call = time.time()\n",
    "    \n",
    "    def generate_summary(self, image: Image.Image, transcription: str = \"\", \n",
    "                        context: List[str] = None) -> Optional[str]:\n",
    "        \"\"\"Generate scholarly summary of document page.\"\"\"\n",
    "        self._apply_rate_limit()\n",
    "        \n",
    "        context_str = \"\"\n",
    "        if context and len(context) > 0:\n",
    "            recent_context = context[-self.config.ROLLING_WINDOW_SIZE:]\n",
    "            context_str = \"\\n\\nContext from previous pages:\\n\" + \"\\n\".join(recent_context)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are a highly specialized historian and archival researcher analyzing an archival photo that may contain one or more document pages.\n",
    "\n",
    "        - Primary source of textual content: Use the transcription text provided whenever available, prioritizing it for all factual and content descriptions.\n",
    "        - Visual analysis: Use the image primarily to describe physical features (seals, stamps, layout, handwritten notes, overlays, partial folds, glued items, postcards) and overall structure.\n",
    "        - Multiple parts: Be aware that a single image may include multiple overlapping documents or layers. Focus your description on the topmost active document, often marked by a visible folio number or placed upfront. Briefly mention secondary or underlying pages only when clearly visible and relevant.\n",
    "        - Authenticity and physical features: Describe archival markers, seals, stamps, paper types, watermarks, or other signs of authenticity.\n",
    "        - Transparency: If handwriting, language, or image quality limits your ability to extract text, explicitly state this rather than guessing or fabricating details.\n",
    "        - Caution: Avoid inferring content not clearly visible or transcribed.\n",
    "        - Languages: Whenever possible, indicate which language is being used across the document.\n",
    "        \n",
    "        **Context from previous pages (if any):**\n",
    "        {context_str}\n",
    "        \n",
    "        **Your summary should:**\n",
    "        - Be concise and scholarly (around 3‚Äì6 sentences).\n",
    "        - Integrate textual and visual analysis smoothly in one narrative paragraph.\n",
    "        - Clearly mention the document type, purpose, people, places, dates, and institutions when available.\n",
    "        - Explicitly state if the transcription was used (e.g., \"Based on available transcription\") or if only partial text could be interpreted.\n",
    "        \n",
    "        Transcription (preferred source): {transcription or 'No transcription available.'}\n",
    "        \n",
    "        **Note: This summary is machine-generated and should be verified by a researcher.**\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.generative_model.generate_content([prompt, image])\n",
    "            return response.text if response else None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating summary: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_embedding(self, image: Image.Image, transcription: str = \"\") -> Optional[List[float]]:\n",
    "        \"\"\"Generate embedding for semantic search.\"\"\"\n",
    "        self._apply_rate_limit()\n",
    "        \n",
    "        visual_prompt = (\n",
    "            \"Describe this historical document image in detail. \"\n",
    "            \"Focus on layout, visual elements, text density, and document type.\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            visual_response = self.generative_model.generate_content([visual_prompt, image])\n",
    "            if not visual_response:\n",
    "                return None\n",
    "            \n",
    "            combined_text = f\"Visual: {visual_response.text}\\nTranscription: {transcription or 'N/A'}\"\n",
    "            embedding_response = genai.embed_content(\n",
    "                model=self.config.EMBEDDING_MODEL, \n",
    "                content=combined_text\n",
    "            )\n",
    "            \n",
    "            return embedding_response.get('embedding') if embedding_response else None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating embedding: {e}\")\n",
    "            return None\n",
    "\n",
    "print(\"‚úÖ Gemini processor defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropy-api-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Tropy API Integration\n",
    "\n",
    "class TropyAPIClient:\n",
    "    \"\"\"Handles all Tropy API interactions.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.session = requests.Session()\n",
    "        self.api_base = config.TROPY_API_BASE\n",
    "    \n",
    "    def fetch_all_items(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Fetch all items from Tropy.\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(f'{self.api_base}/project/items/')\n",
    "            response.raise_for_status()\n",
    "            items = response.json()\n",
    "            logger.info(f\"Fetched {len(items)} items\")\n",
    "            return items\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"Failed to fetch items: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def fetch_photo_details(self, photo_id: int) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Fetch photo metadata.\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(f'{self.api_base}/project/photos/{photo_id}')\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to fetch photo {photo_id}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def fetch_transcription_details(self, transcription_id: int) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Fetch transcription by ID.\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(f'{self.api_base}/project/transcriptions/{transcription_id}')\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to fetch transcription {transcription_id}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def save_note_to_photo(self, photo_id: int, note_text: str) -> bool:\n",
    "        \"\"\"Save note to photo.\"\"\"\n",
    "        try:\n",
    "            post_url = f\"{self.api_base}/project/notes\"\n",
    "            note_data = [('photo', photo_id), ('html', note_text)]\n",
    "            response = self.session.post(post_url, data=note_data)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Apply delay after successful save\n",
    "            time.sleep(self.config.API_NOTE_DELAY)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save note for photo {photo_id}: {e}\")\n",
    "            return False\n",
    "\n",
    "def extract_transcription(photo_data: Dict[str, Any], api_client: TropyAPIClient) -> str:\n",
    "    \"\"\"Extract transcription text from photo data.\"\"\"\n",
    "    transcription_text = \"\"\n",
    "    transcriptions = photo_data.get('transcriptions', [])\n",
    "    \n",
    "    if transcriptions and isinstance(transcriptions, list) and len(transcriptions) > 0:\n",
    "        transcription_id = transcriptions[0]\n",
    "        try:\n",
    "            transcription_data = api_client.fetch_transcription_details(transcription_id)\n",
    "            if transcription_data:\n",
    "                transcription_text = transcription_data.get('text', '')\n",
    "                if transcription_text is None:\n",
    "                    transcription_text = \"\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to fetch transcription {transcription_id}: {e}\")\n",
    "    \n",
    "    return transcription_text.strip()\n",
    "\n",
    "print(\"‚úÖ Tropy API client defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initialize-processors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Initialize All Processors\n",
    "\n",
    "# Create instances of all processors\n",
    "api_client = TropyAPIClient(config)\n",
    "image_processor = ImageProcessor(config)\n",
    "gemini_processor = GeminiProcessor(config)\n",
    "\n",
    "print(\"‚úÖ All processors initialized and ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-selection",
   "metadata": {},
   "source": [
    "## 3. Item Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "item-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Select Items to Process\n",
    "\n",
    "# Fetch all items\n",
    "all_items_data = api_client.fetch_all_items()\n",
    "\n",
    "if not all_items_data:\n",
    "    print(\"‚ùå No items found. Please check Tropy connection.\")\n",
    "    items_to_process = []\n",
    "else:\n",
    "    print(f\"üìö Found {len(all_items_data)} total items in Tropy\\n\")\n",
    "    \n",
    "    print(\"üéØ Select processing mode:\")\n",
    "    print(\"A. All items - Process entire project\")\n",
    "    print(\"B. Single item - Process specific item(s)\")\n",
    "    print(\"C. List - Process items in specific list(s)\")\n",
    "    print(\"\\nExamples: A, B 123, C 1,3\")\n",
    "    \n",
    "    mode_input = input(\"\\nYour choice: \").strip().upper()\n",
    "    \n",
    "    if not mode_input:\n",
    "        mode_input = \"C 1\"  # Default\n",
    "    \n",
    "    # Parse input\n",
    "    parts = mode_input.split()\n",
    "    choice = parts[0]\n",
    "    ids = []\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        id_string = ' '.join(parts[1:])\n",
    "        ids = [id.strip() for id in id_string.split(',') if id.strip()]\n",
    "    \n",
    "    items_to_process = []\n",
    "    \n",
    "    if choice == 'A':\n",
    "        items_to_process = all_items_data\n",
    "        print(f\"\\n‚úÖ Selected ALL items ({len(items_to_process)} items)\")\n",
    "    \n",
    "    elif choice == 'B':\n",
    "        if ids:\n",
    "            for item_id in ids:\n",
    "                for item in all_items_data:\n",
    "                    if str(item.get('id')) == str(item_id):\n",
    "                        items_to_process.append(item)\n",
    "                        print(f\"‚úì Found item {item_id}: {item.get('title', 'Untitled')}\")\n",
    "                        break\n",
    "    \n",
    "    elif choice == 'C':\n",
    "        if ids:\n",
    "            items_set = set()\n",
    "            for list_id in ids:\n",
    "                list_id_int = int(list_id)\n",
    "                list_items = [item for item in all_items_data \n",
    "                             if list_id_int in item.get('lists', [])]\n",
    "                if list_items:\n",
    "                    print(f\"‚úì List {list_id}: {len(list_items)} items\")\n",
    "                    for item in list_items:\n",
    "                        if item['id'] not in items_set:\n",
    "                            items_set.add(item['id'])\n",
    "                            items_to_process.append(item)\n",
    "        else:\n",
    "            # Default to list 1\n",
    "            items_to_process = [item for item in all_items_data \n",
    "                               if 1 in item.get('lists', [])]\n",
    "    \n",
    "    # Summary\n",
    "    if items_to_process:\n",
    "        total_photos = sum(len(item.get('photos', [])) for item in items_to_process)\n",
    "        print(f\"\\nüìä Summary:\")\n",
    "        print(f\"   Items: {len(items_to_process)}\")\n",
    "        print(f\"   Photos: {total_photos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collection-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Analyze Collection & Estimate Time\n",
    "\n",
    "def estimate_processing_time(num_photos: int, seconds_per_photo: float = 2.5) -> Dict[str, Any]:\n",
    "    \"\"\"Estimate processing time.\"\"\"\n",
    "    total_seconds = num_photos * seconds_per_photo\n",
    "    hours = int(total_seconds // 3600)\n",
    "    minutes = int((total_seconds % 3600) // 60)\n",
    "    seconds = int(total_seconds % 60)\n",
    "    \n",
    "    return {\n",
    "        'total_seconds': total_seconds,\n",
    "        'formatted_time': f\"{hours}h {minutes}m {seconds}s\" if hours > 0 else f\"{minutes}m {seconds}s\",\n",
    "        'api_cost_estimate': num_photos * 0.001  # Rough estimate for Gemini Flash\n",
    "    }\n",
    "\n",
    "if 'items_to_process' in locals() and items_to_process:\n",
    "    print(\"\\nüìä Analyzing Collection...\")\n",
    "    \n",
    "    total_photos = sum(len(item.get('photos', [])) for item in items_to_process)\n",
    "    time_estimate = estimate_processing_time(total_photos)\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Processing Estimates:\")\n",
    "    \n",
    "    print(f\"   Photos to process: {total_photos:,}\")\n",
    "    print(f\"   Estimated time: {time_estimate['formatted_time']}\")\n",
    "    print(f\"   Estimated cost: ~${time_estimate['api_cost_estimate']:.2f}\")\n",
    "    \n",
    "    print(\"\\nüí° Recommendations:\")\n",
    "    if total_photos <= 200:\n",
    "        print(\"   ‚ö° Small collection - should complete quickly\")\n",
    "    elif total_photos <= 1000:\n",
    "        print(\"   üí° Medium collection - monitor progress\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Large collection - consider running overnight\")\n",
    "    \n",
    "    print(\"\\nüëâ Ready to process? Run the next cell to start!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-processing",
   "metadata": {},
   "source": [
    "## 4. Main Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processing-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Processing Functions and Classes\n",
    "\n",
    "class BatchProcessor:\n",
    "    \"\"\"Handles batch processing with checkpointing.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.checkpoint_data = self._load_checkpoint()\n",
    "    \n",
    "    def _load_checkpoint(self) -> Dict[str, Any]:\n",
    "        \"\"\"Load checkpoint if exists.\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(self.config.CHECKPOINT_FILE):\n",
    "                with open(self.config.CHECKPOINT_FILE, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                data['processed_photo_ids'] = set(data['processed_photo_ids'])\n",
    "                logger.info(f\"Loaded checkpoint: {len(data['processed_photo_ids'])} photos processed\")\n",
    "                return data\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not load checkpoint: {e}\")\n",
    "        \n",
    "        return {\n",
    "            'processed_photo_ids': set(),\n",
    "            'processed_photos': 0,\n",
    "            'last_update': None,\n",
    "            'embeddings_buffer': [],\n",
    "            'item_summaries_buffer': []\n",
    "        }\n",
    "    \n",
    "    def _save_checkpoint(self):\n",
    "        \"\"\"Save progress to checkpoint.\"\"\"\n",
    "        try:\n",
    "            checkpoint = {\n",
    "                'processed_photo_ids': list(self.checkpoint_data['processed_photo_ids']),\n",
    "                'processed_photos': self.checkpoint_data['processed_photos'],\n",
    "                'last_update': datetime.now().isoformat(),\n",
    "                'embeddings_buffer': self.checkpoint_data['embeddings_buffer'],\n",
    "                'item_summaries_buffer': self.checkpoint_data['item_summaries_buffer']\n",
    "            }\n",
    "            with open(self.config.CHECKPOINT_FILE, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save checkpoint: {e}\")\n",
    "    \n",
    "    def _save_embeddings_batch(self, force: bool = False):\n",
    "        \"\"\"Save embeddings buffer to file.\"\"\"\n",
    "        if not self.checkpoint_data['embeddings_buffer']:\n",
    "            return\n",
    "        \n",
    "        if force or len(self.checkpoint_data['embeddings_buffer']) >= self.config.BATCH_SIZE:\n",
    "            try:\n",
    "                combined_data = {'photo_embeddings': [], 'item_summaries': []}\n",
    "                if os.path.exists(self.config.EMBEDDINGS_FILE):\n",
    "                    with open(self.config.EMBEDDINGS_FILE, 'r') as f:\n",
    "                        existing_data = json.load(f)\n",
    "                        if isinstance(existing_data, list):\n",
    "                            combined_data['photo_embeddings'] = existing_data\n",
    "                        else:\n",
    "                            combined_data = existing_data\n",
    "                \n",
    "                combined_data['photo_embeddings'].extend(self.checkpoint_data['embeddings_buffer'])\n",
    "                \n",
    "                with open(self.config.EMBEDDINGS_FILE, 'w') as f:\n",
    "                    json.dump(combined_data, f, indent=2)\n",
    "                \n",
    "                logger.info(f\"Saved {len(self.checkpoint_data['embeddings_buffer'])} embeddings\")\n",
    "                self.checkpoint_data['embeddings_buffer'] = []\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to save embeddings: {e}\")\n",
    "\n",
    "def generate_item_summary(item_title: str, photo_summaries: List[Dict[str, Any]], \n",
    "                         context_str: str = \"\") -> Optional[str]:\n",
    "    \"\"\"Generate a comprehensive summary for the entire item.\"\"\"\n",
    "    if not photo_summaries:\n",
    "        return None\n",
    "    \n",
    "    # Compile all photo summaries\n",
    "    all_summaries = []\n",
    "    for ps in photo_summaries:\n",
    "        summary_text = f\"Page {ps.get('page', 0)}: {ps.get('summary', '')}\"\n",
    "        all_summaries.append(summary_text)\n",
    "    \n",
    "    combined_summaries = \"\\n\".join(all_summaries)\n",
    "    \n",
    "    # The historian prompt for item summaries\n",
    "    prompt = f\"\"\"\n",
    "    You are a highly specialized historian and archival researcher. You have access to the following photo summaries. Your task is to synthesize a comprehensive, scholarly-level overall summary of this archival item.\n",
    "\n",
    "    Your summary should read as a single, cohesive narrative paragraph (or several coherent paragraphs), integrating all relevant aspects naturally. Please ensure it covers:\n",
    "    \n",
    "    - A clear suggested title for the item at the beginning (write \"Suggested title: ...\" explicitly in the first line).\n",
    "    - What the document is and its general purpose.\n",
    "    - The institutions or departments involved.\n",
    "    - Historical context and relevant dates.\n",
    "    - Physical or archival structure (pages, folders, seals, stamps).\n",
    "    - Main content and themes (cases, people, humanitarian aspects).\n",
    "    - Any key individuals or cases if identifiable.\n",
    "    - Why this item is historically significant.\n",
    "    - Evidence of authenticity (stamps, handwriting, watermarks, archival features).\n",
    "    \n",
    "    **Instructions:**\n",
    "    - Integrate information smoothly rather than listing separate headings.\n",
    "    - Use the photo summaries as your main evidence.\n",
    "    - Be transparent if some information is unclear or missing.\n",
    "    - Do not fabricate or guess beyond provided photo summaries.\n",
    "    \n",
    "    Context from previous pages (if any):\n",
    "    {context_str}\n",
    "    \n",
    "    **Note: This summary is machine-generated and should be reviewed by a researcher.**\n",
    "\n",
    "Current item title: {item_title}\n",
    "\n",
    "Photo summaries:\n",
    "{combined_summaries}\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = gemini_processor.generative_model.generate_content(prompt)\n",
    "        return response.text if response else None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate item summary: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_item_summaries(summaries: List[Dict[str, Any]]) -> None:\n",
    "    \"\"\"Save item summaries to JSON file.\"\"\"\n",
    "    try:\n",
    "        output_file = os.path.join(config.OUTPUT_DIR, \"item_summaries.json\")\n",
    "        os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "        \n",
    "        existing_summaries = []\n",
    "        if os.path.exists(output_file):\n",
    "            with open(output_file, 'r') as f:\n",
    "                existing_summaries = json.load(f)\n",
    "        \n",
    "        existing_summaries.extend(summaries)\n",
    "        \n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(existing_summaries, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Saved {len(summaries)} item summaries to {output_file}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save item summaries: {e}\")\n",
    "\n",
    "print(\"‚úÖ Processing functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Main Processing Loop\n",
    "\n",
    "def process_collection(processor, items, generate_summaries=True, \n",
    "                      generate_embeddings=True, generate_item_summaries=True):\n",
    "    \"\"\"Process items with progress tracking.\"\"\"\n",
    "    \n",
    "    results = {\n",
    "        'processed_photos': 0,\n",
    "        'summaries_created': 0,\n",
    "        'embeddings_created': 0,\n",
    "        'item_summaries_created': 0,\n",
    "        'errors': 0\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    total_photos = sum(len(item.get('photos', [])) for item in items)\n",
    "    \n",
    "    print(f\"\\nüöÄ Starting processing for {len(items)} items ({total_photos} photos)...\")\n",
    "    print(\"üõ°Ô∏è  Checkpointing enabled - safe to interrupt\\n\")\n",
    "    \n",
    "    with tqdm(total=total_photos, desc=\"Processing\", unit=\"photo\") as pbar:\n",
    "        # Update progress bar if resuming\n",
    "        if processor.checkpoint_data['processed_photo_ids']:\n",
    "            pbar.update(len(processor.checkpoint_data['processed_photo_ids']))\n",
    "        \n",
    "        for item in items:\n",
    "            item_id = item.get('id')\n",
    "            item_title = item.get('title', 'Untitled')\n",
    "            photo_ids = item.get('photos', [])\n",
    "            item_photo_summaries = []\n",
    "            \n",
    "            for photo_id in photo_ids:\n",
    "                try:\n",
    "                    # Skip if already processed\n",
    "                    if photo_id in processor.checkpoint_data['processed_photo_ids']:\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "                    \n",
    "                    # Fetch photo data\n",
    "                    photo_data = api_client.fetch_photo_details(photo_id)\n",
    "                    if not photo_data:\n",
    "                        results['errors'] += 1\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "                    \n",
    "                    # Load image\n",
    "                    image = image_processor.load_image(photo_data)\n",
    "                    if not image:\n",
    "                        results['errors'] += 1\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract transcription\n",
    "                    transcription = extract_transcription(photo_data, api_client)\n",
    "                    \n",
    "                    # Generate summary\n",
    "                    summary_text = \"\"\n",
    "                    if generate_summaries:\n",
    "                        summary = gemini_processor.generate_summary(image, transcription)\n",
    "                        if summary:\n",
    "                            # Format and save note\n",
    "                            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "                            header = (\n",
    "                                f\"<div style='background-color: #f9f9f9; padding: 10px; margin-bottom: 10px;'>\"\n",
    "                                f\"<strong>ü§ñ Machine-generated photo summary</strong><br/>\"\n",
    "                                f\"<small>Generated on {timestamp} by {config.GENERATIVE_MODEL}</small>\"\n",
    "                            )\n",
    "                            if transcription:\n",
    "                                header += \"<br/><small>‚úÖ Used transcription data</small>\"\n",
    "                            header += \"</div>\"\n",
    "                            \n",
    "                            formatted_summary = f\"{header}<p>{summary}</p>\"\n",
    "                            \n",
    "                            if api_client.save_note_to_photo(photo_id, formatted_summary):\n",
    "                                results['summaries_created'] += 1\n",
    "                                summary_text = summary\n",
    "                                item_photo_summaries.append({\n",
    "                                    'photo_id': photo_id,\n",
    "                                    'summary': summary,\n",
    "                                    'filename': photo_data.get('filename', ''),\n",
    "                                    'page': photo_data.get('page', 0),\n",
    "                                    'transcription': transcription[:500] if transcription else \"\"\n",
    "                                })\n",
    "                    \n",
    "                    # Generate embedding\n",
    "                    if generate_embeddings:\n",
    "                        embedding = gemini_processor.generate_embedding(image, transcription)\n",
    "                        if embedding:\n",
    "                            processor.checkpoint_data['embeddings_buffer'].append({\n",
    "                                'item_id': item_id,\n",
    "                                'photo_id': photo_id,\n",
    "                                'item_title': item_title,\n",
    "                                'embedding': embedding,\n",
    "                                'summary': summary_text,\n",
    "                                'timestamp': datetime.now().isoformat()\n",
    "                            })\n",
    "                            results['embeddings_created'] += 1\n",
    "                            processor._save_embeddings_batch()\n",
    "                    \n",
    "                    # Update checkpoint\n",
    "                    processor.checkpoint_data['processed_photo_ids'].add(photo_id)\n",
    "                    processor.checkpoint_data['processed_photos'] += 1\n",
    "                    results['processed_photos'] += 1\n",
    "                    \n",
    "                    if processor.checkpoint_data['processed_photos'] % processor.config.CHECKPOINT_INTERVAL == 0:\n",
    "                        processor._save_checkpoint()\n",
    "                    \n",
    "                    del image  # Free memory\n",
    "                    \n",
    "                except KeyboardInterrupt:\n",
    "                    logger.info(\"Interrupted - saving progress...\")\n",
    "                    processor._save_checkpoint()\n",
    "                    processor._save_embeddings_batch(force=True)\n",
    "                    raise\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing photo {photo_id}: {e}\")\n",
    "                    results['errors'] += 1\n",
    "                finally:\n",
    "                    pbar.update(1)\n",
    "            \n",
    "            # Generate item summary if needed\n",
    "            if generate_item_summaries and item_photo_summaries:\n",
    "                try:\n",
    "                    item_summary = generate_item_summary(item_title, item_photo_summaries)\n",
    "                    \n",
    "                    if item_summary:\n",
    "                        # Extract suggested title from the first line\n",
    "                        lines = item_summary.split(\"\\n\")\n",
    "                        suggested_title = \"\"\n",
    "                        for line in lines:\n",
    "                            if line.strip().lower().startswith(\"suggested title:\"):\n",
    "                                suggested_title = line.replace(\"Suggested title:\", \"\").replace(\"suggested title:\", \"\").strip()\n",
    "                                break\n",
    "                        \n",
    "                        # Add to buffer for saving\n",
    "                        processor.checkpoint_data['item_summaries_buffer'].append({\n",
    "                            'item_id': item_id,\n",
    "                            'item_title': item_title,\n",
    "                            'photo_count': len(photo_ids),\n",
    "                            'item_summary': item_summary,\n",
    "                            'suggested_title': suggested_title,\n",
    "                            'timestamp': datetime.now().isoformat(),\n",
    "                            'model': config.GENERATIVE_MODEL\n",
    "                        })\n",
    "                        results['item_summaries_created'] += 1\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed to generate item summary for {item_title}: {e}\")\n",
    "    \n",
    "    # Final save\n",
    "    processor._save_checkpoint()\n",
    "    processor._save_embeddings_batch(force=True)\n",
    "    \n",
    "    # Save item summaries if any\n",
    "    if processor.checkpoint_data['item_summaries_buffer']:\n",
    "        save_item_summaries(processor.checkpoint_data['item_summaries_buffer'])\n",
    "    \n",
    "    # Results summary\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ Processing completed!\")\n",
    "    print(f\"   Photos: {results['processed_photos']}\")\n",
    "    print(f\"   Summaries: {results['summaries_created']}\")\n",
    "    print(f\"   Item summaries: {results['item_summaries_created']}\")\n",
    "    print(f\"   Embeddings: {results['embeddings_created']}\")\n",
    "    print(f\"   Errors: {results['errors']}\")\n",
    "    print(f\"   Time: {elapsed/60:.1f} minutes\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Main processing function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Execute Processing\n",
    "\n",
    "if 'items_to_process' in locals() and items_to_process:\n",
    "    # Create batch processor\n",
    "    batch_processor = BatchProcessor(config)\n",
    "    \n",
    "    # Run processing\n",
    "    results = process_collection(\n",
    "        batch_processor,\n",
    "        items_to_process,\n",
    "        generate_summaries=True,\n",
    "        generate_embeddings=True,\n",
    "        generate_item_summaries=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüí° Next steps:\")\n",
    "    print(\"   1. Run Cell 13 to add item summaries to Tropy\")\n",
    "    print(\"   2. Check your Tropy project for the new notes!\")\n",
    "else:\n",
    "    print(\"‚ùå No items selected. Please run item selection cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-post-processing",
   "metadata": {},
   "source": [
    "## 5. Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add-item-summaries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Add Item Summaries to Tropy\n",
    "\n",
    "def add_item_summaries_to_tropy():\n",
    "    \"\"\"Read generated item summaries and add them as notes to items.\"\"\"\n",
    "    \n",
    "    print(\"üìö Adding item summaries to Tropy...\\n\")\n",
    "    \n",
    "    # Check if item summaries file exists\n",
    "    item_summaries_file = os.path.join(config.OUTPUT_DIR, \"item_summaries.json\")\n",
    "    \n",
    "    if not os.path.exists(item_summaries_file):\n",
    "        print(\"‚ùå No item_summaries.json file found!\")\n",
    "        print(f\"   Expected location: {item_summaries_file}\")\n",
    "        return\n",
    "    \n",
    "    # Load the item summaries\n",
    "    with open(item_summaries_file, 'r') as f:\n",
    "        all_summaries = json.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(all_summaries)} item summaries\\n\")\n",
    "    \n",
    "    added_count = 0\n",
    "    skipped_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    for summary_data in all_summaries:\n",
    "        item_id = summary_data['item_id']\n",
    "        item_title = summary_data.get('item_title', 'Untitled')\n",
    "        item_summary = summary_data.get('item_summary', '')\n",
    "        photo_count = summary_data.get('photo_count', 0)\n",
    "        suggested_title = summary_data.get('suggested_title', '')\n",
    "        \n",
    "        print(f\"üìÑ Processing: '{item_title}' (ID: {item_id})\")\n",
    "        if suggested_title:\n",
    "            print(f\"   Suggested: '{suggested_title}'\")\n",
    "        \n",
    "        if not item_summary:\n",
    "            print(\"   ‚ö†Ô∏è  No summary text found, skipping...\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Get the item to find its photos\n",
    "            item_data = api_client.session.get(f\"{api_client.api_base}/project/items/{item_id}\").json()\n",
    "            photos = item_data.get('photos', [])\n",
    "            \n",
    "            if not photos:\n",
    "                print(\"   ‚ö†Ô∏è  No photos in item, skipping...\")\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Use the LAST photo to attach the item summary\n",
    "            last_photo_id = photos[-1]\n",
    "            \n",
    "            # Check if this photo already has an item summary\n",
    "            photo_data = api_client.fetch_photo_details(last_photo_id)\n",
    "            if photo_data:\n",
    "                notes = photo_data.get('notes', [])\n",
    "                has_item_summary = False\n",
    "                \n",
    "                for note_id in notes:\n",
    "                    note_response = api_client.session.get(f\"{api_client.api_base}/project/notes/{note_id}\")\n",
    "                    if note_response.status_code == 200:\n",
    "                        note_data = note_response.json()\n",
    "                        note_html = note_data.get('html', '')\n",
    "                        if 'Machine-generated overall item summary' in note_html:\n",
    "                            has_item_summary = True\n",
    "                            print(\"   ‚ö†Ô∏è  Item summary already exists, skipping...\")\n",
    "                            skipped_count += 1\n",
    "                            break\n",
    "                \n",
    "                if has_item_summary:\n",
    "                    continue\n",
    "            \n",
    "            # Create the formatted item summary note\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "            \n",
    "            # Gray border for item summaries\n",
    "            item_summary_header = (\n",
    "                \"<div style='background-color: #f5f5f5; padding: 12px; margin-bottom: 10px; \"\n",
    "                \"border-left: 4px solid #999999;'>\"\n",
    "                \"<strong>üìö Machine-generated overall item summary</strong><br/>\"\n",
    "                f\"<small>Generated on {timestamp} by {config.GENERATIVE_MODEL}</small><br/>\"\n",
    "                f\"<small>Based on {photo_count} photo summaries</small>\"\n",
    "            )\n",
    "            if suggested_title:\n",
    "                item_summary_header += f\"<br/><small>üìù Suggested title: {suggested_title}</small>\"\n",
    "            item_summary_header += \"</div>\"\n",
    "            \n",
    "            formatted_summary = f\"{item_summary_header}<p>{item_summary}</p>\"\n",
    "            \n",
    "            # Save the note to Tropy\n",
    "            print(f\"   üíæ Saving to last photo (ID: {last_photo_id})...\")\n",
    "            \n",
    "            if api_client.save_note_to_photo(last_photo_id, formatted_summary):\n",
    "                print(\"   ‚úÖ Item summary added successfully!\")\n",
    "                added_count += 1\n",
    "            else:\n",
    "                print(\"   ‚ùå Failed to save item summary\")\n",
    "                error_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error: {e}\")\n",
    "            error_count += 1\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üìä ITEM SUMMARY ADDITION COMPLETE\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"‚úÖ Added: {added_count} item summaries\")\n",
    "    print(f\"‚ö†Ô∏è  Skipped: {skipped_count}\")\n",
    "    print(f\"‚ùå Errors: {error_count}\")\n",
    "    print(f\"üìã Total: {len(all_summaries)}\")\n",
    "    \n",
    "    if added_count > 0:\n",
    "        print(f\"\\nüéâ Item summaries are attached to the LAST photo of each item!\")\n",
    "\n",
    "# Run the function\n",
    "add_item_summaries_to_tropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-utilities",
   "metadata": {},
   "source": [
    "## 6. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-slate-notes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Clean Slate - Remove AI Notes\n",
    "\n",
    "def get_note_content(note_id):\n",
    "    \"\"\"Extract note content from Tropy API response.\"\"\"\n",
    "    try:\n",
    "        response = api_client.session.get(f\"{api_client.api_base}/project/notes/{note_id}\")\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "        \n",
    "        note_data = response.json()\n",
    "        \n",
    "        # Handle different response structures\n",
    "        if isinstance(note_data, dict):\n",
    "            # Check for html field\n",
    "            if 'html' in note_data:\n",
    "                if isinstance(note_data['html'], dict) and '@value' in note_data['html']:\n",
    "                    return note_data['html']['@value']\n",
    "                else:\n",
    "                    return str(note_data['html'])\n",
    "            # Check for text field\n",
    "            elif 'text' in note_data:\n",
    "                if isinstance(note_data['text'], dict) and '@value' in note_data['text']:\n",
    "                    return note_data['text']['@value']\n",
    "                else:\n",
    "                    return str(note_data['text'])\n",
    "        \n",
    "        return str(note_data)\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Error getting note content: {e}\")\n",
    "        return None\n",
    "\n",
    "def is_ai_generated(note_text):\n",
    "    \"\"\"Check if a note is AI-generated.\"\"\"\n",
    "    if not note_text:\n",
    "        return False\n",
    "    \n",
    "    ai_patterns = [\n",
    "        'Machine-generated photo summary',\n",
    "        'Machine-generated overall item summary',\n",
    "        'ü§ñ Machine-generated photo summary',\n",
    "        'üìö Machine-generated overall item summary',\n",
    "        'Generated on 2025-',\n",
    "        'Generated on 2024-',\n",
    "        'by gemini-1.5-flash',\n",
    "        'ai-generated',\n",
    "        'auto-generated',\n",
    "        'automatically generated',\n",
    "        'claude',\n",
    "        'chatgpt',\n",
    "        'gpt-'\n",
    "    ]\n",
    "    \n",
    "    note_lower = note_text.lower()\n",
    "    return any(pattern.lower() in note_lower for pattern in ai_patterns)\n",
    "\n",
    "def delete_note_multiple_methods(note_id):\n",
    "    \"\"\"Try multiple methods to delete a note.\"\"\"\n",
    "    # Try different endpoints and methods\n",
    "    endpoints_to_try = [\n",
    "        ('DELETE', f'{api_client.api_base}/project/notes/{note_id}'),\n",
    "        ('DELETE', f'{api_client.api_base}/notes/{note_id}'),\n",
    "        ('POST', f'{api_client.api_base}/project/notes/{note_id}/delete'),\n",
    "        ('POST', f'{api_client.api_base}/project/notes/{note_id}', {'action': 'delete'}),\n",
    "        ('PUT', f'{api_client.api_base}/project/notes/{note_id}', {'html': '', 'deleted': True}),\n",
    "    ]\n",
    "    \n",
    "    for method_info in endpoints_to_try:\n",
    "        method = method_info[0]\n",
    "        url = method_info[1]\n",
    "        data = method_info[2] if len(method_info) > 2 else None\n",
    "        \n",
    "        try:\n",
    "            if method == 'DELETE':\n",
    "                res = api_client.session.delete(url)\n",
    "            elif method == 'POST':\n",
    "                res = api_client.session.post(url, data=data)\n",
    "            elif method == 'PUT':\n",
    "                res = api_client.session.put(url, json=data)\n",
    "            \n",
    "            if res.status_code in [200, 204, 404]:\n",
    "                return True\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Try one more method - empty the note\n",
    "    try:\n",
    "        empty_note_url = f'{api_client.api_base}/project/notes/{note_id}'\n",
    "        res = api_client.session.put(empty_note_url, data=[('html', '')])\n",
    "        if res.status_code in [200, 204]:\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return False\n",
    "\n",
    "def remove_ai_notes():\n",
    "    \"\"\"Remove AI-generated notes from Tropy.\"\"\"\n",
    "    \n",
    "    print(\"üßπ CLEAN SLATE - AI Notes Remover\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check connection\n",
    "    try:\n",
    "        test_response = api_client.session.get(f\"{api_client.api_base}/project/items/\")\n",
    "        if test_response.status_code != 200:\n",
    "            print(\"‚ùå Cannot connect to Tropy. Please check if Tropy is running with REST API enabled.\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Connection error: {e}\")\n",
    "        return\n",
    "    \n",
    "    print(\"‚úÖ Connected to Tropy successfully!\\n\")\n",
    "    \n",
    "    # Get all items\n",
    "    all_items = api_client.fetch_all_items()\n",
    "    if not all_items:\n",
    "        print(\"‚ùå No items found in Tropy.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìö Found {len(all_items)} items in Tropy\\n\")\n",
    "    \n",
    "    # Selection menu\n",
    "    print(\"Select what to clean:\")\n",
    "    print(\"A. All items - Remove AI notes from entire project\")\n",
    "    print(\"B. Single item - Remove from specific item(s)\")\n",
    "    print(\"C. List - Remove from specific list(s)\")\n",
    "    \n",
    "    choice_input = input(\"\\nYour choice: \").strip().upper()\n",
    "    \n",
    "    if not choice_input:\n",
    "        print(\"‚ùå No input provided. Cancelled.\")\n",
    "        return\n",
    "    \n",
    "    # Parse input\n",
    "    parts = choice_input.split()\n",
    "    choice = parts[0]\n",
    "    ids = []\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        id_string = ' '.join(parts[1:])\n",
    "        ids = [id.strip() for id in id_string.split(',') if id.strip()]\n",
    "    \n",
    "    # Determine which items to process\n",
    "    items_to_clean = []\n",
    "    \n",
    "    if choice == 'A':\n",
    "        items_to_clean = all_items\n",
    "        print(f\"\\n‚ö†Ô∏è  This will scan ALL {len(items_to_clean)} items for AI notes.\")\n",
    "        \n",
    "    elif choice == 'B':\n",
    "        if ids:\n",
    "            for item_id in ids:\n",
    "                for item in all_items:\n",
    "                    if str(item.get('id')) == str(item_id):\n",
    "                        items_to_clean.append(item)\n",
    "                        print(f\"‚úì Found item {item_id}: {item.get('title', 'Untitled')}\")\n",
    "                        break\n",
    "        else:\n",
    "            print(\"‚ùå No item IDs provided.\")\n",
    "            return\n",
    "            \n",
    "    elif choice == 'C':\n",
    "        if ids:\n",
    "            items_set = set()\n",
    "            for list_id in ids:\n",
    "                list_id_int = int(list_id)\n",
    "                list_items = [item for item in all_items \n",
    "                             if list_id_int in item.get('lists', [])]\n",
    "                if list_items:\n",
    "                    print(f\"‚úì List {list_id}: {len(list_items)} items\")\n",
    "                    for item in list_items:\n",
    "                        if item['id'] not in items_set:\n",
    "                            items_set.add(item['id'])\n",
    "                            items_to_clean.append(item)\n",
    "        else:\n",
    "            print(\"‚ùå No list IDs provided.\")\n",
    "            return\n",
    "    else:\n",
    "        print(\"‚ùå Invalid choice.\")\n",
    "        return\n",
    "    \n",
    "    if not items_to_clean:\n",
    "        print(\"\\n‚ùå No items selected for cleaning.\")\n",
    "        return\n",
    "    \n",
    "    # Scan for AI notes\n",
    "    print(f\"\\nüîç Scanning {len(items_to_clean)} items for AI-generated notes...\")\n",
    "    \n",
    "    ai_notes_found = []\n",
    "    total_photos_scanned = 0\n",
    "    \n",
    "    for item in tqdm(items_to_clean, desc=\"Scanning items\"):\n",
    "        item_id = item.get('id')\n",
    "        photos = item.get('photos', [])\n",
    "        \n",
    "        for photo_id in photos:\n",
    "            total_photos_scanned += 1\n",
    "            \n",
    "            try:\n",
    "                # Get photo details\n",
    "                photo_data = api_client.fetch_photo_details(photo_id)\n",
    "                if not photo_data:\n",
    "                    continue\n",
    "                \n",
    "                # Check each note\n",
    "                notes = photo_data.get('notes', [])\n",
    "                for note_id in notes:\n",
    "                    # Get note content with proper extraction\n",
    "                    note_text = get_note_content(note_id)\n",
    "                    \n",
    "                    if note_text and is_ai_generated(note_text):\n",
    "                        ai_notes_found.append({\n",
    "                            'note_id': note_id,\n",
    "                            'photo_id': photo_id,\n",
    "                            'item_id': item_id,\n",
    "                            'item_title': item.get('title', 'Untitled'),\n",
    "                            'is_item_summary': 'overall item summary' in note_text.lower()\n",
    "                        })\n",
    "                        \n",
    "            except Exception as e:\n",
    "                logger.debug(f\"Error checking photo {photo_id}: {e}\")\n",
    "    \n",
    "    print(f\"\\nüìä Scan complete:\")\n",
    "    print(f\"   Photos scanned: {total_photos_scanned}\")\n",
    "    print(f\"   AI notes found: {len(ai_notes_found)}\")\n",
    "    \n",
    "    if not ai_notes_found:\n",
    "        print(\"\\n‚ú® No AI-generated notes found! Nothing to clean.\")\n",
    "        return\n",
    "    \n",
    "    # Show summary by type\n",
    "    photo_summaries = [n for n in ai_notes_found if not n['is_item_summary']]\n",
    "    item_summaries = [n for n in ai_notes_found if n['is_item_summary']]\n",
    "    \n",
    "    print(f\"\\nüìù Found:\")\n",
    "    print(f\"   Photo summaries: {len(photo_summaries)}\")\n",
    "    print(f\"   Item summaries: {len(item_summaries)}\")\n",
    "    \n",
    "    # Show a few examples\n",
    "    print(\"\\nüìã Examples of notes found:\")\n",
    "    for i, note in enumerate(ai_notes_found[:3]):\n",
    "        note_type = \"Item summary\" if note['is_item_summary'] else \"Photo summary\"\n",
    "        print(f\"   {i+1}. {note_type} in '{note['item_title']}'\")\n",
    "    if len(ai_notes_found) > 3:\n",
    "        print(f\"   ... and {len(ai_notes_found) - 3} more\")\n",
    "    \n",
    "    # Confirmation\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: This will permanently delete {len(ai_notes_found)} notes!\")\n",
    "    confirm = input(\"Proceed with deletion? (y/n): \").strip().lower()\n",
    "    \n",
    "    if confirm not in ['yes', 'y']:\n",
    "        print(\"\\n‚ùå Deletion cancelled. Your notes are safe.\")\n",
    "        return\n",
    "    \n",
    "    # Delete notes\n",
    "    print(f\"\\nüóëÔ∏è  Deleting {len(ai_notes_found)} AI notes...\")\n",
    "    \n",
    "    deleted_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    for note_info in tqdm(ai_notes_found, desc=\"Deleting notes\"):\n",
    "        note_id = note_info['note_id']\n",
    "        \n",
    "        if delete_note_multiple_methods(note_id):\n",
    "            deleted_count += 1\n",
    "        else:\n",
    "            failed_count += 1\n",
    "            logger.debug(f\"Failed to delete note {note_id}\")\n",
    "        \n",
    "        # Small delay to avoid overwhelming the API\n",
    "        if deleted_count % 50 == 0:\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    # Final summary\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üìä CLEAN SLATE COMPLETE\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"‚úÖ Successfully deleted: {deleted_count} notes\")\n",
    "    if failed_count > 0:\n",
    "        print(f\"‚ùå Failed to delete: {failed_count} notes\")\n",
    "    print(f\"‚è±Ô∏è  Total processed: {len(ai_notes_found)}\")\n",
    "    \n",
    "    if deleted_count > 0:\n",
    "        print(f\"\\nüßπ Your Tropy is now cleaner!\")\n",
    "        print(\"üí° You can now run the processing pipeline again if needed.\")\n",
    "\n",
    "# Run the function\n",
    "remove_ai_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Clean Files and Checkpoints (Simple Version)\n",
    "\n",
    "import os\n",
    "\n",
    "# Delete checkpoint\n",
    "if os.path.exists(config.CHECKPOINT_FILE):\n",
    "    os.remove(config.CHECKPOINT_FILE)\n",
    "    print(f\"‚úÖ Deleted checkpoint file: {config.CHECKPOINT_FILE}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  No checkpoint file found: {config.CHECKPOINT_FILE}\")\n",
    "\n",
    "# Delete embeddings file\n",
    "if os.path.exists(config.EMBEDDINGS_FILE):\n",
    "    os.remove(config.EMBEDDINGS_FILE)\n",
    "    print(f\"‚úÖ Deleted embeddings file: {config.EMBEDDINGS_FILE}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  No embeddings file found: {config.EMBEDDINGS_FILE}\")\n",
    "\n",
    "# Delete item summaries file\n",
    "summaries_file = os.path.join(config.OUTPUT_DIR, \"item_summaries.json\")\n",
    "if os.path.exists(summaries_file):\n",
    "    os.remove(summaries_file)\n",
    "    print(f\"‚úÖ Deleted item summaries file: {summaries_file}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  No item summaries file found: {summaries_file}\")\n",
    "\n",
    "# Remove empty output directory if it exists\n",
    "if os.path.exists(config.OUTPUT_DIR) and not os.listdir(config.OUTPUT_DIR):\n",
    "    os.rmdir(config.OUTPUT_DIR)\n",
    "    print(f\"‚úÖ Removed empty output directory: {config.OUTPUT_DIR}\")\n",
    "\n",
    "print(\"\\nüßπ File cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
